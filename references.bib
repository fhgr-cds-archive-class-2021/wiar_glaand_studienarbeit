@article{abucide-armasDataAugmentationBasedTechnique2021,
  title = {A {{Data Augmentation-Based Technique}} for {{Deep Learning Applied}} to {{CFD Simulations}}},
  author = {{Abucide-Armas}, Alvaro and {Portal-Porras}, Koldo and {Fernandez-Gamiz}, Unai and Zulueta, Ekaitz and {Teso-Fz-Beto{\~n}o}, Adrian},
  year = {2021},
  month = jan,
  journal = {Mathematics},
  volume = {9},
  number = {16},
  pages = {1843},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2227-7390},
  doi = {10.3390/math9161843},
  urldate = {2024-01-14},
  abstract = {The computational cost and memory demand required by computational fluid dynamics (CFD) codes simulations can become very high. Therefore, the application of convolutional neural networks (CNN) in this field has been studied owing to its capacity to learn patterns from sets of input data, which can considerably approximate the results of the CFD simulations with relative low errors. DeepCFD code has been taken as a basis and with some slight variations in the parameters of the CNN, while the net is able to solve the Navier{\textendash}Stokes equations for steady turbulent flows with variable input velocities to the domain. In order to acquire extensive input data to the CNN, a data augmentation technique, which considers the similarity principle for fluid dynamics, is implemented. As a consequence, DeepCFD is able to learn the velocities and pressure fields quite accurately, speeding up the time-consuming CFD simulations.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {computational fluids dynamics,convolutional neural networks,data augmentation,DeepCFD},
  file = {/home/glatzl/Zotero/storage/ZM8KZGBX/Abucide-Armas et al. - 2021 - A Data Augmentation-Based Technique for Deep Learn.pdf}
}

@misc{agrawalDonJustAssume2018,
  title = {Don't {{Just Assume}}; {{Look}} and {{Answer}}: {{Overcoming Priors}} for {{Visual Question Answering}}},
  shorttitle = {Don't {{Just Assume}}; {{Look}} and {{Answer}}},
  author = {Agrawal, Aishwarya and Batra, Dhruv and Parikh, Devi and Kembhavi, Aniruddha},
  year = {2018},
  month = jun,
  number = {arXiv:1712.00377},
  eprint = {1712.00377},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1712.00377},
  urldate = {2023-12-13},
  abstract = {A number of studies have found that today's Visual Question Answering (VQA) models are heavily driven by superficial correlations in the training data and lack sufficient image grounding. To encourage development of models geared towards the latter, we propose a new setting for VQA where for every question type, train and test sets have different prior distributions of answers. Specifically, we present new splits of the VQA v1 and VQA v2 datasets, which we call Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2 respectively). First, we evaluate several existing VQA models under this new setting and show that their performance degrades significantly compared to the original VQA setting. Second, we propose a novel Grounded Visual Question Answering model (GVQA) that contains inductive biases and restrictions in the architecture specifically designed to prevent the model from 'cheating' by primarily relying on priors in the training data. Specifically, GVQA explicitly disentangles the recognition of visual concepts present in the image from the identification of plausible answer space for a given question, enabling the model to more robustly generalize across different distributions of answers. GVQA is built off an existing VQA model -- Stacked Attention Networks (SAN). Our experiments demonstrate that GVQA significantly outperforms SAN on both VQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more powerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in several cases. GVQA offers strengths complementary to SAN when trained and evaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more transparent and interpretable than existing VQA models.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/glatzl/Zotero/storage/7UUGB4NY/Agrawal et al. - 2018 - Don't Just Assume\; Look and Answer Overcoming Pri.pdf;/home/glatzl/Zotero/storage/WT648PPA/1712.html}
}

@misc{AlbertinenDiakoniewerkArtenLungenkrebs,
  title = {{Albertinen-Diakoniewerk: Arten von Lungenkrebs}},
  shorttitle = {{Albertinen-Diakoniewerk}},
  journal = {Albertinen-Diakoniewerk},
  urldate = {2022-12-15},
  howpublished = {https://www.albertinen.de/gesundheit-medizin/albertinen-krankenhaus/kliniken-zentren-institute/tumorzentrum/krebs-im-bereich-der-lunge/bronchial-lungenkrebs/arten-von-lungenkrebs/},
  langid = {ngerman},
  file = {/home/glatzl/Zotero/storage/XYZWKKCL/arten-von-lungenkrebs.html}
}

@misc{andersonBottomUpTopDownAttention2018,
  title = {Bottom-{{Up}} and {{Top-Down Attention}} for {{Image Captioning}} and {{Visual Question Answering}}},
  author = {Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  year = {2018},
  month = mar,
  number = {arXiv:1707.07998},
  eprint = {1707.07998},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-10-24},
  abstract = {Top-down visual attention mechanisms have been used extensively in image captioning and visual question answering (VQA) to enable deeper image understanding through fine-grained analysis and even multiple steps of reasoning. In this work, we propose a combined bottom-up and top-down attention mechanism that enables attention to be calculated at the level of objects and other salient image regions. This is the natural basis for attention to be considered. Within our approach, the bottom-up mechanism (based on Faster R-CNN) proposes image regions, each with an associated feature vector, while the top-down mechanism determines feature weightings. Applying this approach to image captioning, our results on the MSCOCO test server establish a new state-of-the-art for the task, achieving CIDEr / SPICE / BLEU-4 scores of 117.9, 21.5 and 36.9, respectively. Demonstrating the broad applicability of the method, applying the same approach to VQA we obtain first place in the 2017 VQA Challenge.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/glatzl/Zotero/storage/KJ7MJLE7/Anderson et al. - 2018 - Bottom-Up and Top-Down Attention for Image Caption.pdf;/home/glatzl/Zotero/storage/TRAQ3FZI/1707.html}
}

@inproceedings{antolVQAVisualQuestion2015,
  title = {{{VQA}}: {{Visual Question Answering}}},
  booktitle = {International {{Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C. Lawrence and Parikh, Devi},
  year = {2015}
}

@article{aquinobritezOptimizationDeepArchitectures2021,
  title = {Optimization of {{Deep Architectures}} for {{EEG Signal Classification}}: {{An AutoML Approach Using Evolutionary Algorithms}}},
  shorttitle = {Optimization of {{Deep Architectures}} for {{EEG Signal Classification}}},
  author = {Aquino Br{\'i}tez, Diego Ariel and Ortiz, Andr{\'e}s and Ortega, Julio and Leon, Javier and Formoso, Marco A. and Gan, John and Escobar, Juan},
  year = {2021},
  month = mar,
  journal = {Sensors},
  volume = {21},
  pages = {2096},
  doi = {10.3390/s21062096},
  abstract = {Electroencephalography (EEG) signal classification is a challenging task due to the low signal-to-noise ratio and the usual presence of artifacts from different sources. Different classification techniques, which are usually based on a predefined set of features extracted from the EEG band power distribution profile, have been previously proposed. However, the classification of EEG still remains a challenge, depending on the experimental conditions and the responses to be captured. In this context, the use of deep neural networks offers new opportunities to improve the classification performance without the use of a predefined set of features. Nevertheless, Deep Learning architectures include a vast number of hyperparameters on which the performance of the model relies. In this paper, we propose a method for optimizing Deep Learning models, not only the hyperparameters, but also their structure, which is able to propose solutions that consist of different architectures due to different layer combinations. The experimental results corroborate that deep architectures optimized by our method outperform the baseline approaches and result in computationally efficient models. Moreover, we demonstrate that optimized architectures improve the energy efficiency with respect to the baseline models.},
  file = {/home/glatzl/Zotero/storage/UJJL2V9F/Aquino Brítez et al. - 2021 - Optimization of Deep Architectures for EEG Signal .pdf}
}

@misc{arxivinsightsIntroductionReinforcementLearning2018,
  title = {An Introduction to {{Reinforcement Learning}}},
  author = {{Arxiv Insights}},
  year = {2018},
  month = apr,
  urldate = {2022-12-12}
}

@misc{AttitudesTravelingUK,
  title = {Attitudes towards Traveling in the {{UK}} 2023},
  journal = {Statista},
  urldate = {2023-12-17},
  abstract = {When asked about \&quot;Attitudes towards traveling\&quot;, most UK respondents pick \&quot;When I'm on vacation, I use my smartphone as a guide\&quot; as an answer.},
  howpublished = {https://www.statista.com/forecasts/997936/attitudes-towards-traveling-in-the-uk},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/6JW6DKD7/attitudes-towards-traveling-in-the-uk.html}
}

@article{baoComputationallyEfficientCFD2020,
  title = {Computationally Efficient {{CFD}} Prediction of Bubbly Flow Using Physics-Guided Deep Learning},
  author = {Bao, Han and Feng, Jinyong and Dinh, Nam and Zhang, Hongbin},
  year = {2020},
  month = oct,
  journal = {International Journal of Multiphase Flow},
  volume = {131},
  pages = {103378},
  issn = {0301-9322},
  doi = {10.1016/j.ijmultiphaseflow.2020.103378},
  urldate = {2024-01-14},
  abstract = {To realize efficient computational fluid dynamics (CFD) prediction of two-phase flow, a multi-scale framework was proposed in this paper by applying a physics-guided data-driven approach. Instrumental to this framework, Feature Similarity Measurement (FSM) technique was developed for error estimation in two-phase flow simulation using coarse-mesh CFD, to achieve a comparable accuracy as fine-mesh simulations with fast-running feature. By defining physics-guided parameters and variable gradients as physical features, FSM has the capability to capture the underlying local patterns in the coarse-mesh CFD simulation. Massive low-fidelity data and respective high-fidelity data are used to explore the underlying information relevant to the main simulation errors and the effects of phenomenological scaling. By learning from previous simulation data, a surrogate model using deep feedforward neural network (DFNN) can be developed and trained to estimate the simulation error of coarse-mesh CFD. In a demonstration case of two-phase bubbly flow, the DFNN model well captured and corrected the unphysical ``peaks'' in the velocity and void fraction profiles near the wall in the coarse-mesh configuration, even for extrapolative predictions. The research documented supports the feasibility of the physics-guided deep learning methods for coarse mesh CFD simulations which has a potential for the efficient industrial design.},
  keywords = {Coarse-mesh CFD,Data similarity,Deep learning,Physical feature,Two-phase bubbly flow},
  file = {/home/glatzl/Zotero/storage/E5FKWAZK/Bao et al. - 2020 - Computationally efficient CFD prediction of bubbly.pdf;/home/glatzl/Zotero/storage/IAQP22MN/S0301932219308043.html}
}

@book{belousovReinforcementLearningAlgorithms2021,
  title = {Reinforcement {{Learning Algorithms}}: {{Analysis}} and {{Applications}}},
  shorttitle = {Reinforcement {{Learning Algorithms}}},
  author = {Belousov, Boris and Abdulsamad, Hany and Klink, Pascal and Parisi, Simone and Peters, Jan},
  year = {2021},
  urldate = {2022-11-06},
  abstract = {This book reviews research developments in diverse areas of reinforcement, presents analysis and real evaluation application, focuses on advanced ideas, algorithms, methods, and applications, and provides recent research on reinforcement learning algorithms},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/CCTVTH3H/978-3-030-41188-6.html}
}

@misc{bowyerCharacteristicsRewardsReinforcement2022,
  title = {Characteristics of {{Rewards}} in {{Reinforcement Learning}}},
  author = {Bowyer, Caleb},
  year = {2022},
  month = jun,
  journal = {MLearning.ai},
  urldate = {2022-11-07},
  abstract = {In previous articles, I described for beginners what reinforcement learning (RL) is{\ldots}},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/PUR4CKEJ/characteristics-of-rewards-in-reinforcement-learning-f5722079aef5.html}
}

@article{bruntonMachineLearningFluid2020,
  title = {Machine {{Learning}} for {{Fluid Mechanics}}},
  author = {Brunton, Steven L. and Noack, Bernd R. and Koumoutsakos, Petros},
  year = {2020},
  journal = {Annual Review of Fluid Mechanics},
  volume = {52},
  number = {1},
  pages = {477--508},
  doi = {10.1146/annurev-fluid-010719-060214},
  urldate = {2024-01-14},
  abstract = {The field of fluid mechanics is rapidly advancing, driven by unprecedented volumes of data from experiments, field measurements, and large-scale simulations at multiple spatiotemporal scales. Machine learning (ML) offers a wealth of techniques to extract information from data that can be translated into knowledge about the underlying fluid mechanics. Moreover, ML algorithms can augment domain knowledge and automate tasks related to flow control and optimization. This article presents an overview of past history, current developments, and emerging opportunities of ML for fluid mechanics. We outline fundamental ML methodologies and discuss their uses for understanding, modeling, optimizing, and controlling fluid flows. The strengths and limitations of these methods are addressed from the perspective of scientific inquiry that considers data as an inherent part of modeling, experiments, and simulations. ML provides a powerful information-processing framework that can augment, and possibly even transform, current lines of fluid mechanics research and industrial applications.},
  keywords = {control,data-driven modeling,machine learning,optimization},
  file = {/home/glatzl/Zotero/storage/PISEYG6S/Brunton et al. - 2020 - Machine Learning for Fluid Mechanics.pdf}
}

@misc{bundesamtfuerstatistikBeschaeftigteTourismusbrancheTausend2023,
  title = {{Besch{\"a}ftigte in der Tourismusbranche - In Tausend Vollzeit{\"a}quivalenten}},
  author = {{Bundesamt f{\"u}r Statistik}},
  year = {2023},
  month = nov,
  number = {ind-d-21.02.30.0809.02.01},
  urldate = {2023-11-21},
  langid = {ngerman}
}

@misc{bundesamtfuerstatistikEntwicklungOekonomischenKerngroessen2022,
  title = {{Entwicklung der {\"o}konomischen Kerngr{\"o}ssen des Tourismus}},
  author = {{Bundesamt f{\"u}r Statistik}},
  year = {2022},
  month = dec,
  number = {je-d-10.02.01.02},
  urldate = {2023-11-21},
  langid = {ngerman}
}

@inproceedings{carettoTwoCalculationProcedures1973,
  title = {Two Calculation Procedures for Steady, Three-Dimensional Flows with Recirculation},
  booktitle = {Proceedings of the {{Third International Conference}} on {{Numerical Methods}} in {{Fluid Mechanics}}},
  author = {Caretto, L. S. and Gosman, A. D. and Patankar, S. V. and Spalding, D. B.},
  editor = {Cabannes, Henri and Temam, Roger},
  year = {1973},
  series = {Lecture {{Notes}} in {{Physics}}},
  pages = {60--68},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/BFb0112677},
  abstract = {Two procedures are described for solving the Navier-Stokes equations for steady, fully three-dimensional flows: both are extensions of earlier methods devised for three-dimensional boundary layers, and have the following common features: (i) the main dependent variables are the velocities and pressure; (ii) the latter are computed on a number of staggered, interlacing grids, each of which is associated with a particular variable; (iii) a hybrid central-upwind difference scheme is employed; and (iv) the solution algorithms are sufficiently implicit to obviate the need to approach the steady state via the time evolution of the flow, as is required by wholly explicit methods.},
  isbn = {978-3-540-38392-5},
  langid = {english},
  keywords = {Continuous Combustion,Difference Equation,Dimensional Boundary Layer,High Reynolds Number,Sparse Grid}
}

@article{chorinNumericalSolutionNavierStokes1967,
  title = {The Numerical Solution of the {{Navier-Stokes}} Equations for an Incompressible Fluid},
  author = {Chorin, Alexandre Joel},
  year = {1967},
  journal = {Bulletin of the American Mathematical Society},
  volume = {73},
  number = {6},
  pages = {928--931},
  issn = {0002-9904, 1936-881X},
  doi = {10.1090/S0002-9904-1967-11853-6},
  urldate = {2023-05-10},
  abstract = {Advancing research. Creating connections.},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/9ZE346RG/Chorin - 1967 - The numerical solution of the Navier-Stokes equati.pdf}
}

@techreport{connywunschArbeitsUndFachkraeftebedarf2014,
  title = {{Arbeits- und Fachkr{\"a}ftebedarf der Schweiz bis 2060}},
  author = {{Conny Wunsch}},
  year = {2014},
  month = oct,
  pages = {140},
  address = {{Basel}},
  institution = {{Abteilung Arbeitsmarkt{\"o}konomie, Wirtschaftswissenschaftliche Fakult{\"a}t, Universit{\"a}t Basel}},
  urldate = {2023-11-21},
  langid = {ngerman}
}

@book{cooperWinningNewProducts2011,
  title = {{Winning at New Products: Creating Value Through Innovation}},
  shorttitle = {{Winning at New Products}},
  author = {Cooper, Robert G.},
  year = {2011},
  month = jul,
  edition = {4},
  publisher = {{Basic Books}},
  address = {{New York}},
  isbn = {978-0-465-02578-7},
  langid = {Englisch}
}

@misc{CRICVQADataset,
  title = {{{CRIC}}: {{A VQA Dataset}} for {{Compositional Reasoning}} on {{Vision}} and {{Commonsense}}},
  urldate = {2023-12-13},
  howpublished = {https://www.computer.org/csdl/journal/tp/2023/05/09905976/1H3ZQYUc7w4},
  file = {/home/glatzl/Zotero/storage/Z37CKTUL/1H3ZQYUc7w4.html}
}

@misc{CVPR2021Open,
  title = {{{CVPR}} 2021 {{Open Access Repository}}},
  urldate = {2023-12-14},
  howpublished = {https://openaccess.thecvf.com/CVPR2021?day=all},
  file = {/home/glatzl/Zotero/storage/CJGE8UGX/CVPR2021.html}
}

@misc{CVPR2021Opena,
  title = {{{CVPR}} 2021 {{Open Access Repository}}},
  urldate = {2023-12-14},
  howpublished = {https://openaccess.thecvf.com/CVPR2021?day=all},
  file = {/home/glatzl/Zotero/storage/KEUPZMDA/CVPR2021.html}
}

@misc{DataMigrationStrategy,
  title = {Data {{Migration}}: {{Strategy}} and {{Best Practices}}},
  shorttitle = {Data {{Migration}}},
  journal = {Talend - A Leader in Data Integration \& Data Integrity},
  urldate = {2023-05-20},
  abstract = {Data migration is the process of moving data from one system to another. See why it's important, and get best practices and key steps.},
  howpublished = {https://www.talend.com/resources/understanding-data-migration-strategies-best-practices/},
  langid = {english}
}

@misc{deeplizardQLearningExplainedReinforcement2018,
  title = {Q-{{Learning Explained}} - {{A Reinforcement Learning Technique}}},
  author = {{deeplizard}},
  year = {2018},
  month = oct,
  urldate = {2022-12-12}
}

@misc{delucaWhatPolicyReinforcement2020,
  title = {What Is a {{Policy}} in {{Reinforcement Learning}}? | {{Baeldung}} on {{Computer Science}}},
  shorttitle = {What Is a {{Policy}} in {{Reinforcement Learning}}?},
  author = {De Luca, Gabriele},
  year = {2020},
  month = aug,
  urldate = {2022-12-11},
  abstract = {Explore the concept of policy for reinforcement learning agents},
  howpublished = {https://www.baeldung.com/cs/ml-policy-reinforcement-learning},
  langid = {american},
  file = {/home/glatzl/Zotero/storage/4B67NPTP/ml-policy-reinforcement-learning.html}
}

@misc{derosaSpringerAerospaceTechnology,
  title = {Springer {{Aerospace Technology}}},
  author = {De Rosa, Sergio and Zheng, Yao and Popova, Elena},
  journal = {Springer},
  urldate = {2023-12-29},
  abstract = {The~series explores the technology and the science related to the aircraft and spacecraft including concept, design, assembly, control and maintenance. The ...},
  howpublished = {https://www.springer.com/series/8613},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/JHI8YN39/8613.html}
}

@misc{devlinBERTPretrainingDeep2019,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  month = may,
  number = {arXiv:1810.04805},
  eprint = {1810.04805},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1810.04805},
  urldate = {2023-09-18},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5\% (7.7\% point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language},
  file = {/home/glatzl/Zotero/storage/DEAW3GG5/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf;/home/glatzl/Zotero/storage/9V3RDDY8/1810.html}
}

@inproceedings{devlinBERTPretrainingDeep2019a,
  title = {{{BERT}}: {{Pre-training}} of {{Deep Bidirectional Transformers}} for {{Language Understanding}}},
  shorttitle = {{{BERT}}},
  booktitle = {Proceedings of the 2019 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}, {{Volume}} 1 ({{Long}} and {{Short Papers}})},
  author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  year = {2019},
  month = jun,
  pages = {4171--4186},
  publisher = {{Association for Computational Linguistics}},
  address = {{Minneapolis, Minnesota}},
  doi = {10.18653/v1/N19-1423},
  urldate = {2023-09-26},
  abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
  file = {/home/glatzl/Zotero/storage/LNZ3XVBE/Devlin et al. - 2019 - BERT Pre-training of Deep Bidirectional Transform.pdf}
}

@misc{DiagnoseLungenkrebsDKG2018,
  title = {Diagnose von {{Lungenkrebs}} | {{DKG}}},
  year = {2018},
  month = apr,
  urldate = {2022-12-14},
  howpublished = {https://www.krebsgesellschaft.de/onko-internetportal/basis-informationen-krebs/krebsarten/definition/diagnose.html},
  file = {/home/glatzl/Zotero/storage/66EJQRWG/diagnose.html}
}

@misc{DnsmasqWikiUbuntuusers,
  title = {Dnsmasq {\guilsinglright} {{Wiki}} {\guilsinglright} Ubuntuusers.De},
  urldate = {2022-01-06},
  howpublished = {https://wiki.ubuntuusers.de/Dnsmasq/},
  file = {/home/glatzl/Zotero/storage/9NU4IPFA/Dnsmasq.html}
}

@misc{elskenNeuralArchitectureSearch2019,
  title = {Neural {{Architecture Search}}: {{A Survey}}},
  shorttitle = {Neural {{Architecture Search}}},
  author = {Elsken, Thomas and Metzen, Jan Hendrik and Hutter, Frank},
  year = {2019},
  month = apr,
  number = {arXiv:1808.05377},
  eprint = {1808.05377},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1808.05377},
  urldate = {2023-09-18},
  abstract = {Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/home/glatzl/Zotero/storage/LQKH5RLU/Elsken et al. - 2019 - Neural Architecture Search A Survey.pdf;/home/glatzl/Zotero/storage/HUQ6QKHK/1808.html}
}

@article{ertlDesignOptimisationEfficient2017,
  title = {Design and Optimisation of an Efficient {{HDF5 I}}/{{O Kernel}} for Massive Parallel Fluid Flow Simulations},
  author = {Ertl, Christoph and Frisch, J{\'e}r{\^o}me and Mundani, Ralf-Peter},
  year = {2017},
  journal = {Concurrency and Computation: Practice and Experience},
  volume = {29},
  number = {24},
  pages = {e4165},
  issn = {1532-0634},
  doi = {10.1002/cpe.4165},
  urldate = {2023-05-12},
  abstract = {More and more massive parallel codes running on several hundreds of thousands of cores are entering the computational science and engineering domain, allowing high-fidelity computations on up to trillions of unknowns for very detailed analyses of the underlying problems. Such runs typically produce gigabytes of data, hindering both efficient storage and (interactive) data exploration. Advanced approaches based on inherently distributed data formats such as hierarchical data format version 5 become necessary here to avoid long latencies when storing the data and to support fast (random) access when retrieving the data for visual processing. This paper shows considerations and implementation aspects of an I/O kernel based on hierarchical data format version 5 that supports fast checkpointing, restarting, and selective visualisation using a single shared output file for an existing computational fluid dynamics framework. This functionality is achieved by including the framework's hierarchical data structure in the file, which also opens the door for additional steering functionality. Finally, the performance of the kernel's write routines are presented. Bandwidths close to the theoretical peak on modern supercomputing clusters were achieved by avoiding file-locking and using collective buffering.},
  langid = {english},
  keywords = {computational fluid dynamics,computational steering,HDF5,high-performance computing,I/O},
  file = {/home/glatzl/Zotero/storage/MGLNC3E8/Ertl et al. - 2017 - Design and optimisation of an efficient HDF5 IO K.pdf;/home/glatzl/Zotero/storage/92BMEHVG/cpe.html}
}

@article{ertlDesignOptimisationEfficient2017a,
  title = {Design and Optimisation of an Efficient {{HDF5 I}}/{{O Kernel}} for Massive Parallel Fluid Flow Simulations},
  author = {Ertl, Christoph and Frisch, J{\'e}r{\^o}me and Mundani, Ralf-Peter},
  year = {2017},
  journal = {Concurrency and Computation: Practice and Experience},
  volume = {29},
  number = {24},
  pages = {e4165},
  issn = {1532-0634},
  doi = {10.1002/cpe.4165},
  urldate = {2023-05-20},
  abstract = {More and more massive parallel codes running on several hundreds of thousands of cores are entering the computational science and engineering domain, allowing high-fidelity computations on up to trillions of unknowns for very detailed analyses of the underlying problems. Such runs typically produce gigabytes of data, hindering both efficient storage and (interactive) data exploration. Advanced approaches based on inherently distributed data formats such as hierarchical data format version 5 become necessary here to avoid long latencies when storing the data and to support fast (random) access when retrieving the data for visual processing. This paper shows considerations and implementation aspects of an I/O kernel based on hierarchical data format version 5 that supports fast checkpointing, restarting, and selective visualisation using a single shared output file for an existing computational fluid dynamics framework. This functionality is achieved by including the framework's hierarchical data structure in the file, which also opens the door for additional steering functionality. Finally, the performance of the kernel's write routines are presented. Bandwidths close to the theoretical peak on modern supercomputing clusters were achieved by avoiding file-locking and using collective buffering.},
  langid = {english},
  keywords = {computational fluid dynamics,computational steering,HDF5,high-performance computing,I/O},
  file = {/home/glatzl/Zotero/storage/S5INEKPL/Ertl et al. - 2017 - Design and optimisation of an efficient HDF5 IO K.pdf;/home/glatzl/Zotero/storage/JJG8E4RS/cpe.html}
}

@misc{fowProjektFutureWork2022,
  title = {Projekt {{Future}} of {{Work}} - {{FH Graub{\"u}nden}}},
  author = {FoW, {\relax FHGR}},
  year = {2022},
  month = jan,
  urldate = {2023-09-26},
  howpublished = {https://www.fhgr.ch/fh-graubuenden/angewandte-zukunftstechnologien/schweizerisches-institut-fuer-informationswissenschaft-sii/projekte/future-of-work/},
  file = {/home/glatzl/Zotero/storage/B5NG9MSB/future-of-work.html}
}

@inproceedings{frischMeasuringComparingScaling2015,
  title = {Measuring and {{Comparing}} the {{Scaling Behaviour}} of a {{High-Performance CFD Code}} on {{Different Supercomputing Infrastructures}}},
  booktitle = {2015 17th {{International Symposium}} on {{Symbolic}} and {{Numeric Algorithms}} for {{Scientific Computing}} ({{SYNASC}})},
  author = {Frisch, J{\'e}r{\^o}me and Mundani, Ralf-Peter},
  year = {2015},
  month = sep,
  pages = {371--378},
  doi = {10.1109/SYNASC.2015.63},
  urldate = {2024-01-14},
  abstract = {Parallel code design is a challenging task especially when addressing petascale systems for massive parallel processing (MPP), i.e. parallel computations on several hundreds of thousands of cores. An in-house computational fluid dynamics code, developed by our group, was designed for such high-fidelity runs in order to exhibit excellent scalability values. Basis for this code is an adaptive hierarchical data structure together with an efficient communication and (numerical) computation scheme that supports MPP. For a detailled scalability analysis, we performed several experiments on two of Germany's national supercomputers up to 140,000 processes. In this paper, we will show the results of those experiments and discuss any bottlenecks that could be observed while solving engineering-based problems such as porous media flows or thermal comfort assessments for problem sizes up to several hundred billion degrees of freedom.},
  file = {/home/glatzl/Zotero/storage/RD4CNAKM/Frisch and Mundani - 2015 - Measuring and Comparing the Scaling Behaviour of a.pdf;/home/glatzl/Zotero/storage/M6TA225C/7426107.html}
}

@article{gaoCRICVQADataset2022,
  title = {{{CRIC}}: {{A VQA Dataset}} for {{Compositional Reasoning}} on {{Vision}} and {{Commonsense}}},
  shorttitle = {{{CRIC}}},
  author = {Gao, Difei and Wang, Ruiping and Shan, Shiguang and Chen, Xilin},
  year = {2022},
  month = sep,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {PP},
  pages = {1--18},
  doi = {10.1109/TPAMI.2022.3210780},
  abstract = {Alternatively inferring on the visual facts and commonsense is fundamental for an advanced VQA system. This ability requires models to go beyond the literal understanding of commonsense. The system should not just treat objects as the entrance to query background knowledge, but fully ground commonsense to the visual world and imagine the possible relationships between objects, e.g., ``fork, can lift, food''. To comprehensively evaluate such abilities, we propose a VQA benchmark, CRIC, which introduces new types of questions about  C ompositional R easoning on v I sion and C ommonsense, and an evaluation metric integrating the correctness of answering and commonsense grounding. To collect such questions and rich additional annotations to support the metric, we also propose an automatic algorithm to generate question samples from the scene graph associated with the images and the relevant knowledge graph. We further analyze several representative types of VQA models on the CRIC dataset. Experimental results show that grounding the commonsense to the image region and joint reasoning on vision and commonsense are still challenging for current approaches. The dataset is available at https://cricvqa.github.io .},
  file = {/home/glatzl/Zotero/storage/KJACT9UF/Gao et al. - 2022 - CRIC A VQA Dataset for Compositional Reasoning on.pdf}
}

@book{geronPraxiseinstiegMachineLearning2020,
  title = {{Praxiseinstieg Machine Learning mit Scikit-Learn, Keras und TensorFlow: Konzepte, Tools und Techniken f{\"u}r intelligente Systeme}},
  shorttitle = {{Praxiseinstieg Machine Learning mit Scikit-Learn, Keras und TensorFlow}},
  author = {G{\'e}ron, Aur{\'e}lien},
  translator = {Rother, Kristian and Demmig, Thomas},
  year = {2020},
  edition = {2. Auflage},
  publisher = {{O'Reilly}},
  address = {{Heidelberg}},
  isbn = {978-3-96009-124-0},
  langid = {german},
  file = {/home/glatzl/Zotero/storage/2F6LJSQG/Géron - 2020 - Praxiseinstieg Machine Learning mit Scikit-Learn, .pdf}
}

@misc{GoogleTravel,
  title = {Google {{Travel}}},
  urldate = {2023-12-17},
  howpublished = {https://www.google.com/travel/},
  file = {/home/glatzl/Zotero/storage/T3272I3Y/travel.html}
}

@article{gormanEcologicalSexualDimorphism2014,
  title = {Ecological {{Sexual Dimorphism}} and {{Environmental Variability}} within a {{Community}} of {{Antarctic Penguins}} ({{Genus Pygoscelis}})},
  author = {Gorman, Kristen B. and Williams, Tony D. and Fraser, William R.},
  year = {2014},
  month = may,
  journal = {PLOS ONE},
  volume = {9},
  number = {3},
  pages = {e90081},
  publisher = {{Public Library of Science}},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0090081},
  urldate = {2022-01-02},
  abstract = {Background Sexual segregation in vertebrate foraging niche is often associated with sexual size dimorphism (SSD), i.e., ecological sexual dimorphism. Although foraging behavior of male and female seabirds can vary markedly, differences in isotopic (carbon, {$\delta$}13C and nitrogen, {$\delta$}15N) foraging niche are generally more pronounced within sexually dimorphic species and during phases when competition for food is greater. We examined ecological sexual dimorphism among sympatric nesting Pygoscelis penguins asking whether environmental variability is associated with differences in male and female pre-breeding foraging niche. We predicted that all Pygoscelis species would forage sex-specifically, and that higher quality winter habitat, i.e., higher or lower sea ice coverage for a given species, would be associated with a more similar foraging niche among the sexes. Results P2/P8 primers reliably amplified DNA of all species. On average, male Pygoscelis penguins are structurally larger than female conspecifics. However, chinstrap penguins were more sexually dimorphic in culmen and flipper features than Ad{\'e}lie and gentoo penguins. Ad{\'e}lies and gentoos were more sexually dimorphic in body mass than chinstraps. Only male and female chinstraps and gentoos occupied separate {$\delta$}15N foraging niches. Strong year effects in {$\delta$}15N signatures were documented for all three species, however, only for Ad{\'e}lies, did yearly variation in {$\delta$}15N signatures tightly correlate with winter sea ice conditions. There was no evidence that variation in sex-specific foraging niche interacted with yearly winter habitat quality. Conclusion Chinstraps were most sexually size dimorphic followed by gentoos and Ad{\'e}lies. Pre-breeding sex-specific foraging niche was associated with overall SSD indices across species; male chinstrap and gentoo penguins were enriched in {$\delta$}15N relative to females. Our results highlight previously unknown trophic pathways that link Pygoscelis penguins with variation in Southern Ocean sea ice suggesting that each sex within a species should respond similarly in pre-breeding trophic foraging to changes in future winter habitat.},
  langid = {english},
  keywords = {Animal sexual behavior,Antarctica,Ecological niches,Foraging,Islands,Isotopes,Penguins,Sea ice},
  file = {/home/glatzl/Zotero/storage/TTE9GG96/Gorman et al. - 2014 - Ecological Sexual Dimorphism and Environmental Var.pdf;/home/glatzl/Zotero/storage/9PNHQ5L2/article.html}
}

@inproceedings{goyalMakingVQAMatter2017,
  title = {Making the {{V}} in {{VQA Matter}}: {{Elevating}} the {{Role}} of {{Image Understanding}} in {{Visual Question Answering}}},
  booktitle = {Conference on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Goyal, Yash and Khot, Tejas and {Summers-Stay}, Douglas and Batra, Dhruv and Parikh, Devi},
  year = {2017}
}

@misc{gravesBayesianFlowNetworks2023,
  title = {Bayesian {{Flow Networks}}},
  author = {Graves, Alex and Srivastava, Rupesh Kumar and Atkinson, Timothy and Gomez, Faustino},
  year = {2023},
  month = aug,
  number = {arXiv:2308.07037},
  eprint = {2308.07037},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2308.07037},
  urldate = {2023-09-18},
  abstract = {This paper introduces Bayesian Flow Networks (BFNs), a new class of generative model in which the parameters of a set of independent distributions are modified with Bayesian inference in the light of noisy data samples, then passed as input to a neural network that outputs a second, interdependent distribution. Starting from a simple prior and iteratively updating the two distributions yields a generative procedure similar to the reverse process of diffusion models; however it is conceptually simpler in that no forward process is required. Discrete and continuous-time loss functions are derived for continuous, discretised and discrete data, along with sample generation procedures. Notably, the network inputs for discrete data lie on the probability simplex, and are therefore natively differentiable, paving the way for gradient-based sample guidance and few-step generation in discrete domains such as language modelling. The loss function directly optimises data compression and places no restrictions on the network architecture. In our experiments BFNs achieve competitive log-likelihoods for image modelling on dynamically binarized MNIST and CIFAR-10, and outperform all known discrete diffusion models on the text8 character-level language modelling task.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/home/glatzl/Zotero/storage/NJ96UT7P/Graves et al. - 2023 - Bayesian Flow Networks.pdf;/home/glatzl/Zotero/storage/T38UWHW3/2308.html}
}

@book{gubelmannProjektmanagementZertifizierungNach2018,
  title = {Projektmanagement - {{Zertifizierung}} Nach {{IPMA}}({{ICB4}})-{{Ebenen D}} Und {{C}}},
  author = {Gubelmann, Josef and Scherler, Heiko and Sommer, Claus-J. and Pifko, Clarisse and Sedlmayer, Martin},
  year = {2018},
  publisher = {{Compendio Bildungsmedien AG}},
  address = {{Z{\"u}rich}}
}

@techreport{hammoudehConciseIntroductionReinforcement2018,
  title = {A {{Concise Introduction}} to {{Reinforcement Learning}}},
  author = {Hammoudeh, Ahmad},
  year = {2018},
  month = feb,
  doi = {10.13140/RG.2.2.31027.53285},
  abstract = {This paper aims to review, and summarize several works and research papers on Reinforcement Learning. Reinforcement learning is an area of Artificial Intelligence; it has emerged as an effective tool towards building artificially intelligent systems and solving sequential decision making problems. Reinforcement Learning has achieved many impressive breakthroughs in the recent years and it was able to surpass human level in many fields; it is able to play and win various games. Historically, reinforcement learning was efficient in solving some control system problems. Nowadays, it has a growing range of applications. This work includes an introduction to reinforcement learning which demonstrates the intuition behind Reinforcement Learning in addition to the main concepts. After that, the remarkable successes of reinforcement learning are highlighted. Consequently, methods and the details for solving reinforcement learning problems are summarized. Thenceforth, data from a wide collection of works in various reinforcement learning applications were reviewed. Finally, the prospects and the challenges of reinforcement learning are discussed.},
  file = {/home/glatzl/Zotero/storage/7KK7298X/Hammoudeh - 2018 - A Concise Introduction to Reinforcement Learning.pdf}
}

@misc{hanyDatensatzLungenkrebsBilder2020,
  title = {Datensatz {{Lungenkrebs-Bilder}}},
  author = {Hany, Mohamed and Shakir, Yasir and Nureyza, Iqrar and Sairam, Vuppala},
  year = {2020},
  month = aug,
  urldate = {2022-12-18}
}

@misc{hasaniLiquidTimeconstantNetworks2020,
  title = {Liquid {{Time-constant Networks}}},
  author = {Hasani, Ramin and Lechner, Mathias and Amini, Alexander and Rus, Daniela and Grosu, Radu},
  year = {2020},
  month = dec,
  number = {arXiv:2006.04439},
  eprint = {2006.04439},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2006.04439},
  urldate = {2023-09-18},
  abstract = {We introduce a new class of time-continuous recurrent neural network models. Instead of declaring a learning system's dynamics by implicit nonlinearities, we construct networks of linear first-order dynamical systems modulated via nonlinear interlinked gates. The resulting models represent dynamical systems with varying (i.e., liquid) time-constants coupled to their hidden state, with outputs being computed by numerical differential equation solvers. These neural networks exhibit stable and bounded behavior, yield superior expressivity within the family of neural ordinary differential equations, and give rise to improved performance on time-series prediction tasks. To demonstrate these properties, we first take a theoretical approach to find bounds over their dynamics and compute their expressive power by the trajectory length measure in latent trajectory space. We then conduct a series of time-series prediction experiments to manifest the approximation capability of Liquid Time-Constant Networks (LTCs) compared to classical and modern RNNs. Code and data are available at https://github.com/raminmh/liquid\_time\_constant\_networks},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/home/glatzl/Zotero/storage/6XMSJARE/Hasani et al. - 2020 - Liquid Time-constant Networks.pdf;/home/glatzl/Zotero/storage/CIUG29UI/2006.html}
}

@misc{HDF5LibraryFile,
  title = {The {{HDF5}}{\textregistered} {{Library}} \& {{File Format}}},
  journal = {The HDF Group},
  urldate = {2023-05-12},
  langid = {american},
  file = {/home/glatzl/Zotero/storage/3NWSQ5IV/hdf5.html}
}

@misc{HDFGroupEnsuring,
  title = {The {{HDF Group}} - Ensuring Long-Term Access and Usability of {{HDF}} Data and Supporting Users of {{HDF}} Technologies},
  urldate = {2023-05-21},
  howpublished = {https://hdfgroup.org/},
  file = {/home/glatzl/Zotero/storage/CMPZ43DU/hdfgroup.org.html}
}

@article{heinzMathematicalSolutionComputational2023,
  title = {A {{Mathematical Solution}} to the {{Computational Fluid Dynamics}} ({{CFD}}) {{Dilemma}}},
  author = {Heinz, Stefan},
  year = {2023},
  month = jan,
  journal = {Mathematics},
  volume = {11},
  number = {14},
  pages = {3199},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2227-7390},
  doi = {10.3390/math11143199},
  urldate = {2024-01-14},
  abstract = {Turbulent flows of practical relevance are often characterized by high Reynolds numbers and solid boundaries. The need to account for flow separation seen in such flows requires the use of (partially) resolving simulation methods on relatively coarse grids. The development of such computational methods is characterized by stagnation. Basically, only a few methods are regularly applied that are known to suffer from significant shortcomings: such methods are often characterized by the significant uncertainty of the predictions due to a variety of adjustable simulation settings, their computational cost can be essential because performance shortcomings need to be compensated by a higher resolution, and there are questions about their reliability because the flow resolving ability is unclear; hence, all such predictions require justification. A substantial reason for this dilemma is of a conceptual nature: the lack of clarity about the essential questions. The paper contrasts the usually applied simulation methods with the minimal error simulation methods presented recently. The comparisons are used to address essential questions about the required characteristics of the desired simulation methods. The advantages of novel simulation methods (including their simplicity, significant computational cost reductions, and controlled resolution ability) are pointed out.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {computational fluid dynamics (CFD),hybrid RANS-LES methods,large eddy simulation (LES),Reynolds-averaged Navier{\textendash}Stokes (RANS) equations},
  file = {/home/glatzl/Zotero/storage/YET9GLSQ/Heinz - 2023 - A Mathematical Solution to the Computational Fluid.pdf}
}

@misc{HelpCenterSwitzerland,
  title = {Help {{Center Switzerland Tourism}}},
  urldate = {2023-12-17},
  howpublished = {https://help.myswitzerland.com/hc/en-us},
  file = {/home/glatzl/Zotero/storage/J3RQ9256/en-us.html}
}

@misc{huangPartialDifferentialEquations2022,
  title = {Partial {{Differential Equations Meet Deep Neural Networks}}: {{A Survey}}},
  shorttitle = {Partial {{Differential Equations Meet Deep Neural Networks}}},
  author = {Huang, Shudong and Feng, Wentao and Tang, Chenwei and Lv, Jiancheng},
  year = {2022},
  month = nov,
  number = {arXiv:2211.05567},
  eprint = {2211.05567},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-04-14},
  abstract = {Many problems in science and engineering can be represented by a set of partial differential equations (PDEs) through mathematical modeling. Mechanism-based computation following PDEs has long been an essential paradigm for studying topics such as computational fluid dynamics, multiphysics simulation, molecular dynamics, or even dynamical systems. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. At the same time, solving PDEs efficiently has been a long-standing challenge. Generally, except for a few differential equations for which analytical solutions are directly available, many more equations must rely on numerical approaches such as the finite difference method, finite element method, finite volume method, and boundary element method to be solved approximately. These numerical methods usually divide a continuous problem domain into discrete points and then concentrate on solving the system at each of those points. Though the effectiveness of these traditional numerical methods, the vast number of iterative operations accompanying each step forward significantly reduces the efficiency. Recently, another equally important paradigm, data-based computation represented by deep learning, has emerged as an effective means of solving PDEs. Surprisingly, a comprehensive review for this interesting subfield is still lacking. This survey aims to categorize and review the current progress on Deep Neural Networks (DNNs) for PDEs. We discuss the literature published in this subfield over the past decades and present them in a common taxonomy, followed by an overview and classification of applications of these related methods in scientific research and engineering scenarios. The origin, developing history, character, sort, as well as the future trends in each potential direction of this subfield are also introduced.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning}
}

@inproceedings{hudsonGQANewDataset2019,
  title = {{{GQA}}: {{A New Dataset}} for {{Real-World Visual Reasoning}} and {{Compositional Question Answering}}},
  shorttitle = {{{GQA}}},
  booktitle = {2019 {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Hudson, Drew A. and Manning, Christopher D.},
  year = {2019},
  month = jun,
  pages = {6693--6702},
  publisher = {{IEEE}},
  address = {{Long Beach, CA, USA}},
  doi = {10.1109/CVPR.2019.00686},
  urldate = {2023-12-13},
  abstract = {We introduce GQA, a new dataset for real-world visual reasoning and compositional question answering, seeking to address key shortcomings of previous VQA datasets. We have developed a strong and robust question engine that leverages Visual Genome scene graph structures to create 22M diverse reasoning questions, which all come with functional programs that represent their semantics. We use the programs to gain tight control over the answer distribution and present a new tunable smoothing technique to mitigate question biases. Accompanying the dataset is a suite of new metrics that evaluate essential qualities such as consistency, grounding and plausibility. A careful analysis is performed for baselines as well as state-of-the-art models, providing fine-grained results for different question types and topologies. Whereas a blind LSTM obtains a mere 42.1\%, and strong VQA models achieve 54.1\%, human performance tops at 89.3\%, offering ample opportunity for new research to explore. We hope GQA will provide an enabling resource for the next generation of models with enhanced robustness, improved consistency, and deeper semantic understanding of vision and language.},
  isbn = {978-1-72813-293-8},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/YA5TLBDD/Hudson and Manning - 2019 - GQA A New Dataset for Real-World Visual Reasoning.pdf}
}

@article{huiFastPressureDistribution2020,
  title = {Fast Pressure Distribution Prediction of Airfoils Using Deep Learning},
  author = {Hui, Xinyu and Bai, Junqiang and Wang, Hui and Zhang, Yang},
  year = {2020},
  month = oct,
  journal = {Aerospace Science and Technology},
  volume = {105},
  pages = {105949},
  issn = {1270-9638},
  doi = {10.1016/j.ast.2020.105949},
  urldate = {2024-01-14},
  abstract = {In the aerodynamic design, optimization of the pressure distribution of airfoils is crucial for the aerodynamic components. Conventionally, the pressure distribution is solved by computational fluid dynamics, which is a time-consuming task. Surrogate modeling can leverage such expense to some extent, but it needs careful shape parameterization schemes for airfoils. As an alternative, deep learning approximates inputs-outputs mapping without solving the efficiency-expensive physical equations and avoids the limitations of particular parameterization methods. Therefore, this paper presents a data-driven approach for predicting the pressure distribution over airfoils based on Convolutional Neural Network (CNN). Given the airfoil geometry, a supervised learning problem is presented for predicting aerodynamic performance. Furthermore, we utilize a universal and flexible parametrization method called Signed Distance Function to improve the performances of CNN. Given the unseen airfoils from the validation dataset to the trained model, our model achieves predicting the pressure coefficient in seconds, with a less than 2\% mean square error.},
  keywords = {Aerodynamic design,Convolutional neural network,Machine learning,Pressure distribution prediction},
  file = {/home/glatzl/Zotero/storage/KSCHBPI2/S1270963820306313.html}
}

@misc{IBMDocs2021,
  title = {{IBM Docs}},
  year = {2021},
  month = dec,
  urldate = {2022-01-06},
  abstract = {IBM Documentation.},
  copyright = {{\textcopyright} Copyright IBM Corporation 2021},
  howpublished = {https://prod.ibmdocs-production-dal-6099123ce774e592a519d7c33db8265e-0000.us-south.containers.appdomain.cloud/docs/de/aix/7.2?topic=d-dig-command},
  langid = {ngerman},
  file = {/home/glatzl/Zotero/storage/BRGIH8S5/7.html}
}

@article{ivanovDecisionTreesEvaluation2020,
  title = {Decision {{Trees}} for {{Evaluation}} of {{Mathematical Competencies}} in the {{Higher Education}}: {{A Case Study}}},
  shorttitle = {Decision {{Trees}} for {{Evaluation}} of {{Mathematical Competencies}} in the {{Higher Education}}},
  author = {Ivanov, Atanas},
  year = {2020},
  month = may,
  journal = {Mathematics},
  volume = {8},
  number = {5},
  pages = {748},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2227-7390},
  doi = {10.3390/math8050748},
  urldate = {2022-10-06},
  abstract = {The assessment of knowledge and skills acquired by the student at each academic stage is crucial for every educational process. This paper proposes and tests an approach based on a structured assessment test for mathematical competencies in higher education and methods for statistical evaluation of the test. A case study is presented for the assessment of knowledge and skills for solving linear algebra and analytic geometry problems by first-year university students. The test includes three main parts{\textemdash}a multiple-choice test with four selectable answers, a solution of two problems with and without the use of specialized mathematical software, and a survey with four questions for each problem. The processing of data is performed mainly by the classification and regression tree (CART) method. Comparative analysis, cross-tables, and reliability statistics were also used. Regression tree models are built to assess the achievements of students and classification tree models for competency assessment on a three-categorical scale. The influence of 31 variables and groups of them on the assessment of achievements and grading of competencies is determined. Regression models show over 94\% fit with data and classification ones{\textemdash}up to 92\% correct classifications. The models can be used to predict students' grades and assess their mathematical competency.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {assessment,classification and regression tree (CART) method,cross-validation,data mining,decision trees,mathematical competency,reliability,science and engineering education,self-assessment},
  file = {/home/glatzl/Zotero/storage/BKJNZFCJ/Ivanov - 2020 - Decision Trees for Evaluation of Mathematical Comp.pdf;/home/glatzl/Zotero/storage/DCZ7RSCS/748.html}
}

@article{ivanovHumansRobotsTourists2023,
  title = {Humans and/or Robots? {{Tourists}}' Preferences towards the Humans{\textendash}Robots Mix in the Service Delivery System},
  shorttitle = {Humans and/or Robots?},
  author = {Ivanov, Stanislav and Webster, Craig and Seyito{\u g}lu, Faruk},
  year = {2023},
  month = mar,
  journal = {Service Business},
  volume = {17},
  number = {1},
  pages = {195--231},
  issn = {1862-8508},
  doi = {10.1007/s11628-022-00517-5},
  urldate = {2023-10-24},
  abstract = {This paper investigates tourists' preferences toward the humans-robots ratio in the service delivery systems of tourism and hospitality companies and the factors that shape them. The sample includes 1537 respondents from nearly 100 countries. The findings show that a higher preferred share of robots is positively associated with the perceived emotional skills of robots, their perceived usefulness in the tourism/hospitality context, perceived robotic service expectations, attitudes towards robots in general, and the male gender. On the other side, it is negatively associated with the perceived disadvantages of robots compared to human servers and the household size of respondents.},
  langid = {english},
  keywords = {Hospitality,Humans{\textendash}robots ratio,Robots,Service delivery system,Tourism},
  file = {/home/glatzl/Zotero/storage/Z936DFFB/Ivanov et al. - 2023 - Humans andor robots Tourists’ preferences toward.pdf}
}

@incollection{jasakPracticalComputationalFluid2020,
  title = {Practical {{Computational Fluid Dynamics}} with the {{Finite Volume Method}}},
  booktitle = {Modeling in {{Engineering Using Innovative Numerical Methods}} for {{Solids}} and {{Fluids}}},
  author = {Jasak, Hrvoje and Uroi{\'c}, Tessa},
  editor = {De Lorenzis, Laura and D{\"u}ster, Alexander},
  year = {2020},
  series = {{{CISM International Centre}} for {{Mechanical Sciences}}},
  pages = {131--150},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-37518-8_4},
  urldate = {2024-01-14},
  abstract = {This chapter covers the fundamental aspects of Computational Fluid Dynamics simulation tools and introduces the terminology and principles of the second order accurate Finite Volume Method with polyhedral mesh support, as implemented in OpenFOAM (Weller et~al. 1998). The first part is dedicated to types and properties of computational meshes, followed by a description of the Finite Volume discretisation for a generic scalar transport equation. Algorithms for pressure-velocity coupling for single{\textendash}phase incompressible Newtonian fluid flow, as described by the Navier-Stokes equations are presented, supported by an overview of algorithms for the solution of the resulting linear system of algebraic equations. Application of the polyhedral FVM solver for real engineering problems is illustrated on some practical examples.},
  isbn = {978-3-030-37518-8},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/FCUY6UWD/Jasak and Uroić - 2020 - Practical Computational Fluid Dynamics with the Fi.pdf}
}

@inproceedings{josephMeshBasedNeural2022,
  title = {Mesh {{Based Neural Networks}} for {{Estimating High Fidelity CFD}} from {{Low Fidelity Input}}},
  booktitle = {{{SoutheastCon}} 2022},
  author = {Joseph, Nikita Susan and Banerjee, Chaity and Reasor, Daniel A. and Pasiliao, Eduardo and Mukherjee, Tathagata},
  year = {2022},
  month = mar,
  pages = {565--574},
  issn = {1558-058X},
  doi = {10.1109/SoutheastCon48659.2022.9764049},
  urldate = {2024-01-14},
  abstract = {In this paper, we propose the design of "mesh-based deep neural network" architectures that explicitly model the spatial dependencies between the nodes of a computational fluid dynamics (CFD) mesh. Our goal is to solve the entrenched partial differential equations for the problem of dynamic high fidelity state space prediction at specific freestream conditions. Building high fidelity CFD models is computationally intensive and requires accurate modeling of the dependencies of the flow field around the aerodynamic system. We build the mesh based neural network for the nodes of the CFD mesh, on and around the aerodynamic geometry and use it to predict the high fidelity models from a low fidelity model. We call these networks mesh based neural networks as they encode the connectivity of the CFD mesh. We conduct experiments using a simulated CFD with pressure data from fluid flow fields, for the task of predicting high fidelity pressure using data from a low fidelity mesh. Our results demonstrate the feasibility of this approach and opens up the possibility of using such systems for boot strapping high fidelity computations and their use in the real world.},
  file = {/home/glatzl/Zotero/storage/RYCBRRQV/Joseph et al. - 2022 - Mesh Based Neural Networks for Estimating High Fid.pdf;/home/glatzl/Zotero/storage/GG96SIYI/9764049.html}
}

@article{kafleVisualQuestionAnswering2017,
  title = {Visual Question Answering: {{Datasets}}, Algorithms, and Future Challenges},
  shorttitle = {Visual Question Answering},
  author = {Kafle, Kushal and Kanan, Christopher},
  year = {2017},
  month = oct,
  journal = {Computer Vision and Image Understanding},
  series = {Language in {{Vision}}},
  volume = {163},
  pages = {3--20},
  issn = {1077-3142},
  doi = {10.1016/j.cviu.2017.06.005},
  urldate = {2023-12-14},
  abstract = {Visual Question Answering (VQA) is a recent problem in computer vision and natural language processing that has garnered a large amount of interest from the deep learning, computer vision, and natural language processing communities. In VQA, an algorithm needs to answer text-based questions about images. Since the release of the first VQA dataset in 2014, additional datasets have been released and many algorithms have been proposed. In this review, we critically examine the current state of VQA in terms of problem formulation, existing datasets, evaluation metrics, and algorithms. In particular, we discuss the limitations of current datasets with regard to their ability to properly train and assess VQA algorithms. We then exhaustively review existing algorithms for VQA. Finally, we discuss possible future directions for VQA and image understanding research.},
  keywords = {Image understanding,Natural language processing,Vision and language},
  file = {/home/glatzl/Zotero/storage/Y6DIKJWY/Kafle and Kanan - 2017 - Visual question answering Datasets, algorithms, a.pdf;/home/glatzl/Zotero/storage/MY9XEHY2/S1077314217301170.html}
}

@article{kenwayEffectiveAdjointApproaches2019,
  title = {Effective Adjoint Approaches for Computational Fluid Dynamics},
  author = {Kenway, Gaetan K. W. and Mader, Charles A. and He, Ping and Martins, Joaquim R. R. A.},
  year = {2019},
  month = oct,
  journal = {Progress in Aerospace Sciences},
  volume = {110},
  pages = {100542},
  issn = {0376-0421},
  doi = {10.1016/j.paerosci.2019.05.002},
  urldate = {2024-01-14},
  abstract = {The adjoint method is used for high-fidelity aerodynamic shape optimization and is an efficient approach for computing the derivatives of a function of interest with respect to a large number of design variables. Over the past few decades, various approaches have been used to implement the adjoint method in computational fluid dynamics solvers. However, further advances in the field are hindered by the lack of performance assessments that compare the various adjoint implementations. Therefore, we propose open benchmarks and report a comprehensive evaluation of the various approaches to adjoint implementation. We also make recommendations on effective approaches, that is, approaches that are efficient, accurate, and have a low implementation cost. We focus on the discrete adjoint method and describe adjoint implementations for two computational fluid dynamics solvers by using various methods for computing the partial derivatives in the adjoint equations and for solving those equations. Both source code transformation and operator-overloading algorithmic differentiation tools are used to compute the partial derivatives, along with finite differencing. We also examine the use of explicit Jacobian and Jacobian-free solution methods. We quantitatively evaluate the speed, scalability, memory usage, and accuracy of the various implementations by running cases that cover a wide range of Mach numbers, Reynolds numbers, mesh topologies, mesh sizes, and number of CPU cores. We conclude that the Jacobian-free method using source code transformation algorithmic differentiation to compute the partial derivatives is the best option because it computes exact derivatives with the lowest CPU time and the lowest memory requirements, and it also scales well up to 10 million cells and over one thousand CPU cores. The superior performance of this approach is primarily due to its Jacobian-free adjoint strategy. The cases presented herein are publicly available and represent platform-independent benchmarks for comparing other current and future adjoint implementations. Our results and discussion provide a guide for discrete adjoint implementations, not only for computational fluid dynamics but also for a wide range of other partial differential equation solvers.},
  keywords = {Adjoint methods,Aerodynamic shape optimization,Algorithmic differentiation,Computational fluid dynamics,Discrete adjoint benchmarks,Sensitivity analysis},
  file = {/home/glatzl/Zotero/storage/SIK2KZKN/S0376042119300120.html}
}

@inproceedings{kervadecRosesAreRed2021,
  title = {Roses {{Are Red}}, {{Violets Are Blue}}... but {{Should VQA Expect Them To}}?},
  booktitle = {Proceedings of the {{IEEE}}/{{CVF Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Kervadec, Corentin and Antipov, Grigory and Baccouche, Moez and Wolf, Christian},
  year = {2021},
  month = jun,
  pages = {2776--2785}
}

@misc{klambauerSelfNormalizingNeuralNetworks2017,
  title = {Self-{{Normalizing Neural Networks}}},
  author = {Klambauer, G{\"u}nter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
  year = {2017},
  month = sep,
  number = {arXiv:1706.02515},
  eprint = {1706.02515},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1706.02515},
  urldate = {2023-12-04},
  abstract = {Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are "scaled exponential linear units" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance -- even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: github.com/bioinf-jku/SNNs.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/glatzl/Zotero/storage/PBFCDN3L/Klambauer et al. - 2017 - Self-Normalizing Neural Networks.pdf;/home/glatzl/Zotero/storage/5CTZFY5B/1706.html}
}

@article{kochkovMachineLearningAccelerated2021,
  title = {Machine Learning{\textendash}Accelerated Computational Fluid Dynamics},
  author = {Kochkov, Dmitrii and Smith, Jamie A. and Alieva, Ayya and Wang, Qing and Brenner, Michael P. and Hoyer, Stephan},
  year = {2021},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {21},
  pages = {e2101784118},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2101784118},
  urldate = {2024-01-14},
  abstract = {Numerical simulation of fluids plays an essential role in modeling many physical phenomena, such as weather, climate, aerodynamics, and plasma physics. Fluids are well described by the Navier{\textendash}Stokes equations, but solving these equations at scale remains daunting, limited by the computational cost of resolving the smallest spatiotemporal features. This leads to unfavorable trade-offs between accuracy and tractability. Here we use end-to-end deep learning to improve approximations inside computational fluid dynamics for modeling two-dimensional turbulent flows. For both direct numerical simulation of turbulence and large-eddy simulation, our results are as accurate as baseline solvers with 8 to 10{\texttimes} finer resolution in each spatial dimension, resulting in 40- to 80-fold computational speedups. Our method remains stable during long simulations and generalizes to forcing functions and Reynolds numbers outside of the flows where it is trained, in contrast to black-box machine-learning approaches. Our approach exemplifies how scientific computing can leverage machine learning and hardware accelerators to improve simulations without sacrificing accuracy or generalization.},
  file = {/home/glatzl/Zotero/storage/K67TIUJE/Kochkov et al. - 2021 - Machine learning–accelerated computational fluid d.pdf}
}

@inproceedings{kodraVisualQuestionAnswering2018,
  title = {Visual {{Question Answering Agent}} with {{Visual}} and {{Textual Attention}}},
  booktitle = {Proceedings of the 2018 {{International Conference}} on {{E-business}} and {{Mobile Commerce}}},
  author = {Kodra, Lorena and Me{\c c}e, Elinda Kajo},
  year = {2018},
  month = may,
  series = {{{ICEMC}} '18},
  pages = {34--38},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3230467.3230476},
  urldate = {2023-10-24},
  abstract = {Advancements in computer vision, natural language processing and deep learning techniques have resulted in the creation of intelligent systems that have achieved impressive results in the visually grounded tasks such as image captioning and visual question answering (VQA). VQA is a task that can be used to evaluate a system's capacity to understand an image. It requires an intelligent agent to answer a natural language question about an image. The agent must ground the question into the image and return a natural language answer. One of the latest techniques proposed to tackle this task is the attention mechanism. It allows the agent to focus on specific parts of the input in order to answer the question. In this paper we propose a novel long short-term memory (LSTM) architecture that uses dual attention to focus on specific question words and parts of the input image in order to generate the answer. We evaluate our solution on the recently proposed Visual 7W dataset and show that it performs better than state of the art. Additionally, we propose two new question types for this dataset in order to improve model evaluation. We also make a qualitative analysis of the results and show the strength and weakness of our agent.},
  isbn = {978-1-4503-6430-0},
  keywords = {artificial intelligence,attention mechanism,long short-term memory,natural language processing,Visual question answering}
}

@article{krishnaVisualGenomeConnecting2017,
  title = {Visual {{Genome}}: {{Connecting Language}} and {{Vision Using Crowdsourced Dense Image Annotations}}},
  shorttitle = {Visual {{Genome}}},
  author = {Krishna, Ranjay and Zhu, Yuke and Groth, Oliver and Johnson, Justin and Hata, Kenji and Kravitz, Joshua and Chen, Stephanie and Kalantidis, Yannis and Li, Li-Jia and Shamma, David A. and Bernstein, Michael S. and {Fei-Fei}, Li},
  year = {2017},
  month = may,
  journal = {International Journal of Computer Vision},
  volume = {123},
  number = {1},
  pages = {32--73},
  issn = {1573-1405},
  doi = {10.1007/s11263-016-0981-7},
  urldate = {2023-10-24},
  abstract = {Despite progress in perceptual tasks such as image classification, computers still perform poorly on cognitive tasks such as image description and question answering. Cognition is core to tasks that involve not just recognizing, but reasoning about our visual world. However, models used to tackle the rich content in images for cognitive tasks are still being trained using the same datasets designed for perceptual tasks. To achieve success at cognitive tasks, models need to understand the interactions and relationships between objects in an image. When asked ``What vehicle is the person riding?'', computers will need to identify the objects in an image as well as the relationships riding(man, carriage) and pulling(horse, carriage) to answer correctly that ``the person is riding a horse-drawn carriage.'' In this paper, we present the Visual Genome dataset to enable the modeling of such relationships. We collect dense annotations of objects, attributes, and relationships within each image to learn these models. Specifically, our dataset contains over 108K images where each image has an average of \$\$35\$\$objects, \$\$26\$\$attributes, and \$\$21\$\$pairwise relationships between objects. We canonicalize the objects, attributes, relationships, and noun phrases in region descriptions and questions answer pairs to WordNet synsets. Together, these annotations represent the densest and largest dataset of image descriptions, objects, attributes, relationships, and question answer pairs.},
  langid = {english},
  keywords = {Attributes,Computer vision,Crowdsourcing,Dataset,Image,Knowledge,Language,Objects,Question answering,Relationships,Scene graph},
  file = {/home/glatzl/Zotero/storage/3ZXKSUZM/Krishna et al. - 2017 - Visual Genome Connecting Language and Vision Usin.pdf}
}

@book{lavinSimulationIntelligenceNew2021,
  title = {Simulation {{Intelligence}}: {{Towards}} a {{New Generation}} of {{Scientific Methods}}},
  shorttitle = {Simulation {{Intelligence}}},
  author = {Lavin, Alexander and Zenil, Hector and Paige, Brooks and Krakauer, David and Gottschlich, Justin and Mattson, Tim and Anandkumar, Anima and Choudry, Sanjay and Rocki, Kamil and Baydin, At{\i}l{\i}m and Prunkl, Carina and Isayev, Olexandr and Peterson, Erik and McMahon, Peter and Macke, Jakob and Cranmer, Kyle and Zhang, Jiaxin and Wainwright, Haruko and Hanuka, Adi and Pfeffer, Avi},
  year = {2021},
  month = dec,
  abstract = {The original "Seven Motifs" set forth a roadmap of essential methods for the field of scientific computing, where a motif is an algorithmic method that captures a pattern of computation and data movement. We present the "Nine Motifs of Simulation Intelligence", a roadmap for the development and integration of the essential algorithms necessary for a merger of scientific computing, scientific simulation, and artificial intelligence. We call this merger simulation intelligence (SI), for short. We argue the motifs of simulation intelligence are interconnected and interdependent, much like the components within the layers of an operating system. Using this metaphor, we explore the nature of each layer of the simulation intelligence operating system stack (SI-stack) and the motifs therein: (1) Multi-physics and multi-scale modeling; (2) Surrogate modeling and emulation; (3) Simulation-based inference; (4) Causal modeling and inference; (5) Agent-based modeling; (6) Probabilistic programming; (7) Differentiable programming; (8) Open-ended optimization; (9) Machine programming. We believe coordinated efforts between motifs offers immense opportunity to accelerate scientific discovery, from solving inverse problems in synthetic biology and climate science, to directing nuclear energy experiments and predicting emergent behavior in socioeconomic settings. We elaborate on each layer of the SI-stack, detailing the state-of-art methods, presenting examples to highlight challenges and opportunities, and advocating for specific ways to advance the motifs and the synergies from their combinations. Advancing and integrating these technologies can enable a robust and efficient hypothesis-simulation-analysis type of scientific method, which we introduce with several use-cases for human-machine teaming and automated science.},
  file = {/home/glatzl/Zotero/storage/WF8NR9H8/Lavin et al. - 2021 - Simulation Intelligence Towards a New Generation .pdf}
}

@inproceedings{liAdversarialVQANew2021,
  title = {Adversarial {{VQA}}: {{A New Benchmark}} for {{Evaluating}} the {{Robustness}} of {{VQA Models}}},
  booktitle = {2021 {{IEEE}}/{{CVF International Conference}} on {{Computer Vision}}, {{ICCV}} 2021, {{Montreal}}, {{QC}}, {{Canada}}, {{October}} 10-17, 2021},
  author = {Li, Linjie and Lei, Jie and Gan, Zhe and Liu, Jingjing},
  year = {2021},
  pages = {2022--2031},
  publisher = {{IEEE}},
  doi = {10.1109/ICCV48922.2021.00205}
}

@inproceedings{liBoostingVisualQuestion2020,
  title = {Boosting {{Visual Question Answering}} with {{Context-aware Knowledge Aggregation}}},
  booktitle = {Proceedings of the 28th {{ACM International Conference}} on {{Multimedia}}},
  author = {Li, Guohao and Wang, Xin and Zhu, Wenwu},
  year = {2020},
  month = oct,
  series = {{{MM}} '20},
  pages = {1227--1235},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3394171.3413943},
  urldate = {2023-10-24},
  abstract = {Given an image and a natural language question, Visual Question Answering (VQA) aims at answering the textual question correctly. Most VQA approaches in literature targets at finding answers to the questions solely based on analyzing the given images and questions alone. Other works that try to incorporate external knowledge into VQA adopt a query-based search on knowledge graphs to obtain the answer. However, these works suffer from the following problem: the model training process heavily relies on the ground-truth knowledge facts which serve as supervised information --- missing these ground-truth knowledge facts during training will lead to failures in producing the correct answers. To solve the challenging issue, we propose a Knowledge Graph Augmented (KG-Aug) model which conducts context-aware knowledge aggregation on external knowledge graphs, requiring no ground-truth knowledge facts for extra supervision. The proposed KG-Aug model is capable of retrieving context-aware knowledge subgraphs given visual images and textual questions, and learning to aggregate the useful image- and question-dependent knowledge which is then utilized to boost the accuracy in answering visual questions. We carry out extensive experiments to validate the effectiveness of our proposed KG-Aug models against several baseline approaches on various datasets.},
  isbn = {978-1-4503-7988-5},
  keywords = {knowledge graph,visual question answering}
}

@article{liDefiningHighQualityAnswers2021,
  title = {Defining {{High-Quality Answers}} on a {{Chinese Tourism Q}}\&amp;{{A Platform}} in {{Terms}} of {{Information Needs}}},
  author = {Li, Lei and Song, Xue and Liu, Shujun and Huang, Kun},
  year = {2021},
  month = dec,
  journal = {Sustainability},
  volume = {13},
  number = {24},
  pages = {13884},
  doi = {10.3390/su132413884}
}

@article{liMachineLearningInternet2020,
  title = {Machine Learning in Internet Search Query Selection for Tourism Forecasting},
  author = {Li, Xin and Li, Hengyun and Pan, Bing and Law, Rob},
  year = {2020},
  month = jul,
  journal = {Journal of Travel Research},
  volume = {60},
  number = {6},
  pages = {1213--1231},
  doi = {10.1177/0047287520934871}
}

@misc{linRevisitingRoleLanguage2023,
  title = {Revisiting the {{Role}} of {{Language Priors}} in {{Vision-Language Models}}},
  author = {Lin, Zhiqiu and Chen, Xinyue and Pathak, Deepak and Zhang, Pengchuan and Ramanan, Deva},
  year = {2023},
  month = oct,
  number = {arXiv:2306.01879},
  eprint = {2306.01879},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2306.01879},
  urldate = {2023-10-24},
  abstract = {Vision-language models (VLMs) are impactful in part because they can be applied to a variety of visual understanding tasks in a zero-shot fashion, without any fine-tuning. We study \${\textbackslash}textit\{generative VLMs\}\$ that are trained for next-word generation given an image. We explore their zero-shot performance on the illustrative task of image-text retrieval across 8 popular vision-language benchmarks. Our first observation is that they can be repurposed for discriminative tasks (such as image-text retrieval) by simply computing the match score of generating a particular text string given an image. We call this probabilistic score the \${\textbackslash}textit\{Visual Generative Pre-Training Score\}\$ (VisualGPTScore). While the VisualGPTScore produces near-perfect accuracy on some retrieval benchmarks, it yields poor accuracy on others. We analyze this behavior through a probabilistic lens, pointing out that some benchmarks inadvertently capture unnatural language distributions by creating adversarial but unlikely text captions. In fact, we demonstrate that even a "blind" language model that ignores any image evidence can sometimes outperform all prior art, reminiscent of similar challenges faced by the visual-question answering (VQA) community many years ago. We derive a probabilistic post-processing scheme that controls for the amount of linguistic bias in generative VLMs at test time without having to retrain or fine-tune the model. We show that the VisualGPTScore, when appropriately debiased, is a strong zero-shot baseline for vision-language understanding, oftentimes producing state-of-the-art accuracy.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/glatzl/Zotero/storage/S2YQ2U96/Lin et al. - 2023 - Revisiting the Role of Language Priors in Vision-L.pdf;/home/glatzl/Zotero/storage/N7Q85XPV/2306.html}
}

@article{liVisualQuestionAnswering2020,
  title = {Visual Question Answering with Attention Transfer and a Cross-Modal Gating Mechanism},
  author = {Li, Wei and Sun, Jianhui and Liu, Ge and Zhao, Linglan and Fang, Xiangzhong},
  year = {2020},
  month = may,
  journal = {Pattern Recognition Letters},
  volume = {133},
  pages = {334--340},
  issn = {0167-8655},
  doi = {10.1016/j.patrec.2020.02.031},
  urldate = {2023-10-24},
  abstract = {Visual question answering (VQA) is challenging since it requires to understand both language information and corresponding visual contents. A lot of efforts have been made to capture single-step language and visual interactions. However, answering complex questions requires multiple steps of reasoning which gradually adjusts the region of interest to the most relevant part of the given image, which has not been well investigated. To integrate question related object relations into attention mechanism, we propose a multi-step attention architecture to facilitate the modeling of multi-modal correlations. Firstly, an attention transfer mechanism is integrated to gradually adjust the region of interest considering reasoning representation of questions. Secondly, we propose a cross-modal gating strategy to filter out irrelevant information based on multi-modal correlations. Finally, we achieve the state-of-the-art performance on the VQA 1.0 dataset and favorable results on the VQA 2.0 dataset, which verifies the effectiveness of our proposed method.},
  keywords = {Attention,Gating,Visual question answering},
  file = {/home/glatzl/Zotero/storage/B5ZUPT39/S0167865520300763.html}
}

@article{luDeepXDEDeepLearning2021,
  title = {{{DeepXDE}}: {{A Deep Learning Library}} for {{Solving Differential Equations}}},
  shorttitle = {{{DeepXDE}}},
  author = {Lu, Lu and Meng, Xuhui and Mao, Zhiping and Karniadakis, George Em},
  year = {2021},
  month = jan,
  journal = {SIAM Review},
  volume = {63},
  number = {1},
  pages = {208--228},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10.1137/19M1274067},
  urldate = {2023-05-17},
  abstract = {In this paper, we propose a personalized dialogue generation system, which combines reinforcement learning techniques with an attention-based hierarchical recurrent encoderdecoder model. Firstly, we incorporate user-specific information into the decoder to capture user's background information and speaking style. Secondly, we employ reinforcement learning techniques to maximize future reward in dialogue, which enables our system to generate topic-coherent, informative and grammatical responses. Moreover, we propose three types of rewards to characterize good conversations. Finally, we compare the performance of the following reinforcement learning methods in dialogue generation: policy gradient, Q-learning, and actor-critic algorithms. We conduct experiments to verify the effectiveness of the proposed model on two dialogue datasets. Experimental results demonstrate that our model can generate better personalized dialogues for different users. Quantitatively, our method achieves better performance than the state-of-the-art dialogue systems in terms of BLEU score, perplexity, and human evaluation.},
  file = {/home/glatzl/Zotero/storage/XWICT752/Lu et al. - 2021 - DeepXDE A Deep Learning Library for Solving Diffe.pdf}
}

@misc{LungCancerScreening2013,
  title = {Lung {{Cancer Screening}} | {{UF Health Jacksonville}} | {{University}} of {{Florida Health}}},
  year = {2013},
  month = jul,
  urldate = {2022-12-14},
  abstract = {Lung Cancer Screening at the UF Health Cancer Center in Jacksonville, Florida.},
  howpublished = {https://ufhealthjax.org/cancer/lung/screening.aspx},
  file = {/home/glatzl/Zotero/storage/YRZMNUP6/screening.html}
}

@incollection{luViLBERTPretrainingTaskagnostic2019,
  title = {{{ViLBERT}}: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks},
  shorttitle = {{{ViLBERT}}},
  booktitle = {Proceedings of the 33rd {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
  year = {2019},
  month = dec,
  number = {2},
  pages = {13--23},
  publisher = {{Curran Associates Inc.}},
  address = {{Red Hook, NY, USA}},
  urldate = {2023-10-24},
  abstract = {We present ViLBERT (short for Vision-and-Language BERT), a model for learning task-agnostic joint representations of image content and natural language. We extend the popular BERT architecture to a multi-modal two-stream model, processing both visual and textual inputs in separate streams that interact through co-attentional transformer layers. We pretrain our model through two proxy tasks on the large, automatically collected Conceptual Captions dataset and then transfer it to multiple established vision-and-language tasks {\textendash} visual question answering, visual commonsense reasoning, referring expressions, and caption-based image retrieval {\textendash} by making only minor additions to the base architecture. We observe significant improvements across tasks compared to existing task-specific models {\textendash} achieving state-of-the-art on all four tasks. Our work represents a shift away from learning groundings between vision and language only as part of task training and towards treating visual grounding as a pretrainable and transferable capability.},
  file = {/home/glatzl/Zotero/storage/CCH2ZU4Z/Lu et al. - 2019 - ViLBERT pretraining task-agnostic visiolinguistic.pdf}
}

@misc{MajorTypesLung2022,
  title = {Major {{Types}} of {{Lung Cancer}} and the {{Most Common}}},
  year = {2022},
  month = sep,
  journal = {Verywell Health},
  urldate = {2022-12-14},
  abstract = {The most common types of lung cancer can vary depending on age, sex, and smoking status. They have also changed over time. Learn more.},
  chapter = {Verywell},
  howpublished = {https://www.verywellhealth.com/what-is-the-most-common-type-of-lung-cancer-2249359},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/F247M9N8/what-is-the-most-common-type-of-lung-cancer-2249359.html}
}

@misc{maRobustVisualQuestion2023,
  title = {Robust {{Visual Question Answering}}: {{Datasets}}, {{Methods}}, and {{Future Challenges}}},
  shorttitle = {Robust {{Visual Question Answering}}},
  author = {Ma, Jie and Wang, Pinghui and Kong, Dechen and Wang, Zewei and Liu, Jun and Pei, Hongbin and Zhao, Junzhou},
  year = {2023},
  month = jul,
  number = {arXiv:2307.11471},
  eprint = {2307.11471},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-12-14},
  abstract = {Visual question answering requires a system to provide an accurate natural language answer given an image and a natural language question. However, it is widely recognized that previous generic VQA methods often exhibit a tendency to memorize biases present in the training data rather than learning proper behaviors, such as grounding images before predicting answers. Therefore, these methods usually achieve high in-distribution but poor out-of-distribution performance. In recent years, various datasets and debiasing methods have been proposed to evaluate and enhance the VQA robustness, respectively. This paper provides the first comprehensive survey focused on this emerging fashion. Specifically, we first provide an overview of the development process of datasets from in-distribution and out-of-distribution perspectives. Then, we examine the evaluation metrics employed by these datasets. Thirdly, we propose a typology that presents the development process, similarities and differences, robustness comparison, and technical features of existing debiasing methods. Furthermore, we analyze and discuss the robustness of representative vision-and-language pre-training models on VQA. Finally, through a thorough review of the available literature and experimental analysis, we discuss the key areas for future research from various viewpoints.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,I.2.10},
  file = {/home/glatzl/Zotero/storage/EAA2H6PM/Ma et al. - 2023 - Robust Visual Question Answering Datasets, Method.pdf;/home/glatzl/Zotero/storage/SEMUBLSB/2307.html}
}

@incollection{mavriplisProgressCFDDiscretizations2019,
  title = {Progress in {{CFD Discretizations}}, {{Algorithms}} and {{Solvers}} for {{Aerodynamic Flows}}},
  booktitle = {{{AIAA Aviation}} 2019 {{Forum}}},
  author = {Mavriplis, Dimitri J.},
  year = {2019},
  month = jun,
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/6.2019-2944},
  urldate = {2024-01-14},
  file = {/home/glatzl/Zotero/storage/DXTTR4FT/6.html}
}

@misc{meierOpenEndedReinforcementLearning2022,
  title = {Open-{{Ended Reinforcement Learning}} with {{Neural Reward Functions}}},
  author = {Meier, Robert and Mujika, Asier},
  year = {2022},
  month = feb,
  urldate = {2022-10-27},
  howpublished = {https://as.inf.ethz.ch/research/open\_ended\_RL/main.html},
  file = {/home/glatzl/Zotero/storage/YM2UYSAJ/main.html}
}

@misc{meta.aiPapersCodeOverview,
  title = {Papers with {{Code}} - {{An Overview}} of {{Activation Functions}}},
  author = {Meta.Ai},
  urldate = {2023-12-04},
  abstract = {Activation functions are functions that we apply in neural networks after (typically) applying an affine transformation combining weights and input features. They are typically non-linear functions. The rectified linear unit, or ReLU, has been the most popular in the past decade, although the choice is architecture dependent and many alternatives have emerged in recent years. In this section, you will find a constantly updating list of activation functions.},
  howpublished = {https://paperswithcode.com/methods/category/activation-functions},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/NW2RWH32/activation-functions.html}
}

@misc{MicrosoftErklaertWas2020,
  title = {{Microsoft erkl{\"a}rt: Was ist Deep Learning? Definition \& Funktionen von DL | News Center Microsoft}},
  shorttitle = {{Microsoft erkl{\"a}rt}},
  year = {2020},
  month = apr,
  journal = {News Center Microsoft Deutschland},
  urldate = {2022-12-14},
  abstract = {Wie funktioniert Deep Learning und was ist der Unterschied zu Machine Learning? Eine einfache Definition und praktische Beispiele gibt es hier.},
  howpublished = {https://news.microsoft.com/de-de/microsoft-erklaert-was-ist-deep-learning-definition-funktionen-von-dl/},
  langid = {ngerman},
  file = {/home/glatzl/Zotero/storage/7LJJRGKH/microsoft-erklaert-was-ist-deep-learning-definition-funktionen-von-dl.html}
}

@article{moseleyFastApproximateSimulation,
  title = {Fast Approximate Simulation of Seismic Waves with Deep Learning},
  author = {Moseley, B and Markham, A and {Nissen-Meyer}, T},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/3EJWV3ML/Moseley et al. - Fast approximate simulation of seismic waves with .pdf}
}

@misc{moseleyFastApproximateSimulation2018,
  title = {Fast Approximate Simulation of Seismic Waves with Deep Learning},
  author = {Moseley, Benjamin and Markham, Andrew and {Nissen-Meyer}, Tarje},
  year = {2018},
  month = jul,
  journal = {arXiv.org},
  urldate = {2023-05-30},
  abstract = {We simulate the response of acoustic seismic waves in horizontally layered media using a deep neural network. In contrast to traditional finite-difference modelling techniques our network is able to directly approximate the recorded seismic response at multiple receiver locations in a single inference step, without needing to iteratively model the seismic wavefield through time. This results in an order of magnitude reduction in simulation time from the order of 1 s for FD modelling to the order of 0.1 s using our approach. Such a speed improvement could lead to real-time seismic simulation applications and benefit seismic inversion algorithms based on forward modelling, such as full waveform inversion. Our proof of concept deep neural network is trained using 50,000 synthetic examples of seismic waves propagating through different 2D horizontally layered velocity models. We discuss how our approach could be extended to arbitrary velocity models. Our deep neural network design is inspired by the WaveNet architecture used for speech synthesis. We also investigate using deep neural networks for simulating the full seismic wavefield and for carrying out seismic inversion directly.},
  howpublished = {https://arxiv.org/abs/1807.06873v1},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/MTM98LR4/Moseley et al. - 2018 - Fast approximate simulation of seismic waves with .pdf}
}

@misc{moseleyFastApproximateSimulation2018a,
  title = {Fast Approximate Simulation of Seismic Waves with Deep Learning},
  author = {Moseley, Benjamin and Markham, Andrew and {Nissen-Meyer}, Tarje},
  year = {2018},
  month = jul,
  journal = {arXiv.org},
  urldate = {2023-05-30},
  abstract = {We simulate the response of acoustic seismic waves in horizontally layered media using a deep neural network. In contrast to traditional finite-difference modelling techniques our network is able to directly approximate the recorded seismic response at multiple receiver locations in a single inference step, without needing to iteratively model the seismic wavefield through time. This results in an order of magnitude reduction in simulation time from the order of 1 s for FD modelling to the order of 0.1 s using our approach. Such a speed improvement could lead to real-time seismic simulation applications and benefit seismic inversion algorithms based on forward modelling, such as full waveform inversion. Our proof of concept deep neural network is trained using 50,000 synthetic examples of seismic waves propagating through different 2D horizontally layered velocity models. We discuss how our approach could be extended to arbitrary velocity models. Our deep neural network design is inspired by the WaveNet architecture used for speech synthesis. We also investigate using deep neural networks for simulating the full seismic wavefield and for carrying out seismic inversion directly.},
  howpublished = {https://arxiv.org/abs/1807.06873v1},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/4D9KL3FU/Moseley et al. - 2018 - Fast approximate simulation of seismic waves with .pdf}
}

@inproceedings{muralidharPhyFlowPhysicsGuidedDeep2021,
  title = {{{PhyFlow}}: {{Physics-Guided Deep Learning}} for {{Generating Interpretable 3D Flow Fields}}},
  shorttitle = {{{PhyFlow}}},
  booktitle = {2021 {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}})},
  author = {Muralidhar, Nikhil and Bu, Jie and Cao, Ze and Raj, Neil and Ramakrishnan, Naren and Tafti, Danesh and Karpatne, Anuj},
  year = {2021},
  month = dec,
  pages = {1246--1251},
  issn = {2374-8486},
  doi = {10.1109/ICDM51629.2021.00152},
  urldate = {2024-01-14},
  abstract = {Generating flow fields (such as pressure and velocity fields) in 3D space is a fundamental task in computational fluid dynamics (CFD), with applications across a vast spectrum of science and engineering problems. An important class of fluid flow problems in CFD is multi-phase flow, where dispersed solid particles are present in the fluid flow. Despite recent developments in deep learning (DL) for CFD applications, current state-of-the-art is still unable to model 3D flow fields, especially in multi-phase flow settings. It is with this goal that we introduce PhyFlow, a novel physics-guided deep learning architecture for modeling 3D multi-phase fluid flows, designed to mimic the popular projection method for solving fluid flows in CFD simulations. We demonstrate that PhyFlow generates high quality flow fields and yields a 49.61\% improvement over other state-of-the-art baselines. We also test the quality of PhyFlow based fields by employing them in downstream tasks like particle drag force prediction and demonstrate state-of-the-art results, improving upon the previous best models by 9.89\%. Finally, we demonstrate the consistency of PhyFlow predictions with known underlying physics governing equations. Our source code and data are available online *.*tinyurl.com/mjkcrsdw},
  file = {/home/glatzl/Zotero/storage/6XDGUJDN/Muralidhar et al. - 2021 - PhyFlow Physics-Guided Deep Learning for Generati.pdf;/home/glatzl/Zotero/storage/32U3MHTY/9679054.html}
}

@article{murataNonlinearModeDecomposition2020,
  title = {Nonlinear Mode Decomposition with Convolutional Neural Networks for Fluid Dynamics},
  author = {Murata, Takaaki and Fukami, Kai and Fukagata, Koji},
  year = {2020},
  month = jan,
  journal = {Journal of Fluid Mechanics},
  volume = {882},
  pages = {A13},
  publisher = {{Cambridge University Press}},
  issn = {0022-1120, 1469-7645},
  doi = {10.1017/jfm.2019.822},
  urldate = {2024-01-14},
  abstract = {, We present a new nonlinear mode decomposition method to visualize decomposed flow fields, named the mode decomposing convolutional neural network autoencoder (MD-CNN-AE). The proposed method is applied to a flow around a circular cylinder at the Reynolds number ReD=100ReD=100Re\_\{D\}=100 as a test case. The flow attributes are mapped into two modes in the latent space and then these two modes are visualized in the physical space. Because the MD-CNN-AEs with nonlinear activation functions show lower reconstruction errors than the proper orthogonal decomposition (POD), the nonlinearity contained in the activation function is considered the key to improving the capability of the model. It is found by applying POD to each field decomposed using the MD-CNN-AE with hyperbolic tangent activation such that a single nonlinear MD-CNN-AE mode contains multiple orthogonal bases, in contrast to the linear methods, i.e. POD and MD-CNN-AE with linear activation. We further assess the proposed MD-CNN-AE by applying it to a transient process of a circular cylinder wake in order to examine its capability for flows containing high-order spatial modes. The present results suggest a great potential for the nonlinear MD-CNN-AE to be used for feature extraction of flow fields in lower dimensions than POD, while retaining interpretable relationships with the conventional POD modes.},
  langid = {english},
  keywords = {computational methods,low-dimensional models,vortex shedding},
  file = {/home/glatzl/Zotero/storage/9FFW63VM/Murata et al. - 2020 - Nonlinear mode decomposition with convolutional ne.pdf}
}

@misc{NginxReverseProxy2019,
  title = {Nginx {{Reverse Proxy}}: {{How}} to {{Setup}} and {{Configure}} | {{PhoenixNAP KB}}},
  shorttitle = {Nginx {{Reverse Proxy}}},
  year = {2019},
  month = jan,
  journal = {Knowledge Base by phoenixNAP},
  urldate = {2022-01-06},
  abstract = {Learn How to Setup a NGINX Reverse Proxy With Examples. NGINX includes load-balancing, security, \& optimization enabling. Use NGINX as a Reverse Proxy!},
  howpublished = {https://phoenixnap.com/kb/nginx-reverse-proxy},
  langid = {american},
  file = {/home/glatzl/Zotero/storage/5FFCNW8U/nginx-reverse-proxy.html}
}

@article{normansusstrunkLargeLanguageModels2023,
  title = {Large {{Language Models}} versus {{Foundation Models}} for {{Assessing}} the {{Future-Readiness}} of {{Skills}}},
  author = {{Norman S{\"u}sstrunk} and {Albert Weichselbraun} and {Roger Waldvogel}},
  year = {2023},
  month = nov,
  volume = {Nachhaltige Information -- Information f{\"u}r Nachhaltigkeit},
  pages = {294--311},
  doi = {10.5281/zenodo.10009338},
  urldate = {2023-12-02},
  abstract = {Das 17. Internationale Symposium f{\"u}r Informationswissenschaft (ISI 2023) tr{\"a}gt das Motto "Nachhaltige Information {\textemdash} Information f{\"u}r Nachhaltigkeit" und basiert auf den Zielen der Agenda 2030 der Vereinten Nationen. Die Informationswissenschaft tr{\"a}gt wesentlich zur Verwirklichung dieser Agenda-Ziele bei.Neue Technologien wie maschinelles Lernen und K{\"u}nstliche Intelligenz erweitern die Perspektiven der Informationswissenschaft und fordern eine intensive Auseinandersetzung mit dem Thema Bewahrung und Bereitstellung von Information.Traditionell versammelt das Symposium Expertinnen und Experten, die Forschungsprojekte pr{\"a}sentieren und aktuelle Themen wissenschaftlich diskutieren. Das diesj{\"a}hrige Programm umfasst Sessions zu Bildungsmaterialien, der digitalen Bibliothek, zu Datenvisualisierung, Usability, Forschungsdaten und anderen Themen, die die Ziele der Agenda 2030 widerspiegeln.Das Symposium w{\"u}rdigt auch junge Talente mit dem Gerhard-Lustig-Preis f{\"u}r die beste Master-Abschlussarbeit und bietet Doktoranden ein Kolloquium zur Pr{\"a}sentation ihrer Forschung.},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/8BEDNZ8D/Nachhaltige Information – Information für Nachhalt.pdf}
}

@misc{PalmerArchipelagoAntarctica,
  title = {Palmer {{Archipelago}} ({{Antarctica}}) Penguin Data},
  urldate = {2022-01-04},
  abstract = {Drop in replacement for Iris Dataset},
  howpublished = {https://kaggle.com/parulpandey/palmer-archipelago-antarctica-penguin-data},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/ETUH966C/palmer-archipelago-antarctica-penguin-data.html}
}

@misc{PostGIS,
  title = {{{PostGIS}}},
  urldate = {2023-05-20},
  howpublished = {https://postgis.net/},
  file = {/home/glatzl/Zotero/storage/7J8UPN42/postgis.net.html}
}

@misc{powellWhatReinforcementLearning2022,
  title = {What Is {{Reinforcement Learning}} {\textendash} {{Castle Labs}}},
  author = {Powell, Warren},
  year = {2022},
  month = jan,
  urldate = {2022-10-06},
  langid = {american},
  file = {/home/glatzl/Zotero/storage/UE9AGZT7/what-is-rl.html}
}

@article{raissiHiddenFluidMechanics2020,
  title = {Hidden Fluid Mechanics: {{Learning}} Velocity and Pressure Fields from Flow Visualizations},
  shorttitle = {Hidden Fluid Mechanics},
  author = {Raissi, Maziar and Yazdani, Alireza and Karniadakis, George Em},
  year = {2020},
  month = feb,
  journal = {Science},
  volume = {367},
  number = {6481},
  pages = {1026--1030},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.aaw4741},
  urldate = {2024-01-14},
  abstract = {For centuries, flow visualization has been the art of making fluid motion visible in physical and biological systems. Although such flow patterns can be, in principle, described by the Navier-Stokes equations, extracting the velocity and pressure fields directly from the images is challenging. We addressed this problem by developing hidden fluid mechanics (HFM), a physics-informed deep-learning framework capable of encoding the Navier-Stokes equations into the neural networks while being agnostic to the geometry or the initial and boundary conditions. We demonstrate HFM for several physical and biomedical problems by extracting quantitative information for which direct measurements may not be possible. HFM is robust to low resolution and substantial noise in the observation data, which is important for potential applications.},
  file = {/home/glatzl/Zotero/storage/IKVCJ8P6/Raissi et al. - 2020 - Hidden fluid mechanics Learning velocity and pres.pdf}
}

@misc{RaspberryPiSSH2020,
  title = {{Raspberry Pi: SSH aktivieren unter Raspbian (SD-Karte, raspi-config, Desktop)}},
  shorttitle = {{Raspberry Pi}},
  year = {2020},
  month = mar,
  journal = {Einplatinencomputer},
  urldate = {2022-01-06},
  abstract = {Mit Hilfe einer SSH-Verbindung kann der Zugriff auf die Kommandozeile des Raspberry Pi ohne Bildschirm, Maus und Tastatur erfolgen (unter Raspbian). Das ist insbesondere beim Headless-Betrieb hilfreich und notwendig. Wie man beim Raspberry Pi unter Raspbian den SSH Zugriff aktivieren kann, erl{\"a}utere ich dir im Folgenden. Raspbian: SSH ist standardm{\"a}{\ss}ig deaktiviert Der SSH-Server ist auf [{\ldots}]},
  langid = {ngerman},
  file = {/home/glatzl/Zotero/storage/7WIINM3H/raspberry-pi-ssh-aktivieren-raspbian.html}
}

@article{reissOptimizationTheoryBehavioural1987,
  title = {Optimization Theory in Behavioural Ecology},
  author = {Reiss, Michael J.},
  year = {1987},
  month = dec,
  journal = {Journal of Biological Education},
  volume = {21},
  number = {4},
  pages = {241--247},
  publisher = {{Routledge}},
  issn = {0021-9266},
  doi = {10.1080/00219266.1987.9654909},
  urldate = {2022-12-11},
  abstract = {Optimization theory in biology is concerned with discovering the constraints under which organisms exist. In behavioural ecology, optimization studies have served to identify the selective factors which determine the strategies animals use to organize their lives. In the last ten years tremendous advances have been made in our understanding of why animals behave as they do. Techniques borrowed from economics such as games theory have helped to explain the existence of alternative behavioural strategies. A great deal of field research is still needed to test many of the recent predictions of behavioural ecology.}
}

@inproceedings{rengarajanReinforcementLearningSparse2022,
  title = {Reinforcement {{Learning}} with {{Sparse Rewards}} Using {{Guidance}} from {{Offline Demonstration}}},
  booktitle = {International {{Conference}} on {{Learning Representations}}},
  author = {Rengarajan, Desik and Vaidya, Gargi and Sarvesh, Akshay and Kalathil, Dileep and Shakkottai, Srinivas},
  year = {2022},
  month = feb,
  urldate = {2022-11-17},
  abstract = {A major challenge in real-world reinforcement learning (RL) is the sparsity of reward feedback. Often, what is available is an intuitive but sparse reward function that only indicates whether the task is completed partially or fully. However, the lack of carefully designed, fine grain feedback implies that most existing RL algorithms fail to learn an acceptable policy in a reasonable time frame. This is because of the large number of exploration actions that the policy has to perform before it gets any useful feedback that it can learn from. In this work, we address this challenging problem by developing an algorithm that exploits the offline demonstration data generated by \{a sub-optimal behavior policy\} for faster and efficient online RL in such sparse reward settings. The proposed algorithm, which we call the Learning Online with Guidance Offline (LOGO) algorithm, merges a policy improvement step with an additional policy guidance step by using the offline demonstration data. The key idea is that by obtaining guidance from - not imitating - the offline \{data\}, LOGO orients its policy in the manner of the sub-optimal \{policy\}, while yet being able to learn beyond and approach optimality. We provide a theoretical analysis of our algorithm, and provide a lower bound on the performance improvement in each learning episode. We also extend our algorithm to the even more challenging incomplete observation setting, where the demonstration data contains only a censored version of the true state observation. We demonstrate the superior performance of our algorithm over state-of-the-art approaches on a number of benchmark environments with sparse rewards \{and censored state\}. Further, we demonstrate the value of our approach via implementing LOGO on a mobile robot for trajectory tracking and obstacle avoidance, where it shows excellent performance.},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/FEDW43GA/Rengarajan et al. - 2022 - Reinforcement Learning with Sparse Rewards using G.pdf;/home/glatzl/Zotero/storage/FWI2W23X/forum.html}
}

@misc{researchEPICWayEvaluate2021,
  title = {An {{EPIC}} Way to Evaluate Reward Functions},
  author = {Research, DeepMind Safety},
  year = {2021},
  month = apr,
  journal = {Medium},
  urldate = {2022-11-24},
  abstract = {How can you tell if you have a good reward function? EPIC provides a fast and reliable way to evaluate reward functions.},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/NSNFIUYS/an-epic-way-to-evaluate-reward-functions-c2c6d41b61cc.html}
}

@article{ReverseProxy2021,
  title = {{Reverse Proxy}},
  year = {2021},
  month = jan,
  journal = {Wikipedia},
  urldate = {2022-01-06},
  abstract = {Ein Reverse-Proxy ist ein Proxy in einem Rechnernetz, der Ressourcen f{\"u}r einen externen Client von einem oder mehreren internen Servern holt. Die Umsetzung der Adresse ist atypisch und der Richtung des Aufrufes entgegengesetzt (deutsch ,,umgekehrter Proxy``). Die wahre Adresse des internen Zielsystems bleibt dem externen Client verborgen. Das unterscheidet ihn vom typischen (Forward-)Proxy, der mehreren Clients eines internen (in sich abgeschlossenen) Netzes den Zugriff auf ein externes Netz gew{\"a}hrt.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {ngerman},
  annotation = {Page Version ID: 207562039},
  file = {/home/glatzl/Zotero/storage/4J96QHUK/index.html}
}

@article{rozovDatadrivenPredictionUnsteady2021,
  title = {Data-Driven Prediction of Unsteady Pressure Distributions Based on Deep Learning},
  author = {Rozov, Vladyslav and Breitsamter, Christian},
  year = {2021},
  month = jul,
  journal = {Journal of Fluids and Structures},
  volume = {104},
  pages = {103316},
  issn = {0889-9746},
  doi = {10.1016/j.jfluidstructs.2021.103316},
  urldate = {2024-01-14},
  abstract = {In the present work, an efficient Reduced-Order Model is developed for the prediction of motion-induced unsteady pressure distributions. The model is trained on the basis of synthetic data generated by full-order Computational Fluid Dynamics (CFD) simulations. The nonlinear identification task is to predict a snapshot representing the pressure distribution for the current time step based on respective snapshots of previous time steps and applied excitation. Once a Reduced-Order Model is conditioned on training data, it can predict sequences of the pressure distribution in a recurrent manner based on the excitation signal. Hence, it is able to capture the motion-induced nonlinear unsteady aerodynamics for a given configuration at fixed free-stream conditions. In this way, computationally extensive CFD simulations can be substituted by the application of the more efficient Reduced-Order Model. The nonlinear behavior of the aerodynamic system is captured based on a deep convolutional neural network. The performance of the Reduced-Order Model is demonstrated based on the LANN (Lockheed-Georgia, Air Force Flight Dynamics Laboratory, NASA-Langley and NLR) wing performing high-amplitude pitching motion in transonic flow. The unsteady aerodynamics of the considered test case is dominated by nonlinear effects due to complex moving shock structures both on the upper and lower surface of the wing. The Reduced-Order Model yields a superior prediction accuracy at a speed-up of more than three orders of magnitude compared to the employed CFD method.},
  keywords = {Computational Fluid Dynamics,Deep learning,LANN model,Reduced-Order Models,Transonic flight,Unsteady aerodynamics},
  file = {/home/glatzl/Zotero/storage/ZMP4GI6D/S0889974621000992.html}
}

@article{safayaKUISAILSemEval2020Task2020,
  title = {{{KUISAIL}} at {{SemEval-2020 Task}} 12: {{BERT-CNN}} for {{Offensive Speech Identification}} in {{Social Media}}},
  author = {Safaya, Ali and Abdullatif, Moutasem and Yuret, Deniz},
  year = {2020},
  journal = {ArXiv},
  volume = {abs/2007.13184}
}

@inproceedings{safayaKUISAILSemEval2020Task2020a,
  title = {{{KUISAIL}} at {{SemEval-2020 Task}} 12: {{BERT-CNN}} for {{Offensive Speech Identification}} in {{Social Media}}},
  shorttitle = {{{KUISAIL}} at {{SemEval-2020 Task}} 12},
  booktitle = {Proceedings of the {{Fourteenth Workshop}} on {{Semantic Evaluation}}},
  author = {Safaya, Ali and Abdullatif, Moutasem and Yuret, Deniz},
  year = {2020},
  month = dec,
  pages = {2054--2059},
  publisher = {{International Committee for Computational Linguistics}},
  address = {{Barcelona (online)}},
  doi = {10.18653/v1/2020.semeval-1.271},
  urldate = {2023-09-26},
  abstract = {In this paper, we describe our approach to utilize pre-trained BERT models with Convolutional Neural Networks for sub-task A of the Multilingual Offensive Language Identification shared task (OffensEval 2020), which is a part of the SemEval 2020. We show that combining CNN with BERT is better than using BERT on its own, and we emphasize the importance of utilizing pre-trained language models for downstream tasks. Our system, ranked 4th with macro averaged F1-Score of 0.897 in Arabic, 4th with score of 0.843 in Greek, and 3rd with score of 0.814 in Turkish. Additionally, we present ArabicBERT, a set of pre-trained transformer language models for Arabic that we share with the community.},
  file = {/home/glatzl/Zotero/storage/EYIQRN6H/Safaya et al. - 2020 - KUISAIL at SemEval-2020 Task 12 BERT-CNN for Offe.pdf}
}

@inproceedings{satopaaFindingKneedleHaystack2011,
  title = {Finding a "{{Kneedle}}" in a {{Haystack}}: {{Detecting Knee Points}} in {{System Behavior}}},
  shorttitle = {Finding a "{{Kneedle}}" in a {{Haystack}}},
  booktitle = {2011 31st {{International Conference}} on {{Distributed Computing Systems Workshops}}},
  author = {Satopaa, Ville and Albrecht, Jeannie and Irwin, David and Raghavan, Barath},
  year = {2011},
  month = jun,
  pages = {166--171},
  issn = {2332-5666},
  doi = {10.1109/ICDCSW.2011.20},
  abstract = {Computer systems often reach a point at which the relative cost to increase some tunable parameter is no longer worth the corresponding performance benefit. These "knees'' typically represent beneficial points that system designers have long selected to best balance inherent trade-offs. While prior work largely uses ad hoc, system-specific approaches to detect knees, we present Kneedle, a general approach to on line and off line knee detection that is applicable to a wide range of systems. We define a knee formally for continuous functions using the mathematical concept of curvature and compare our definition against alternatives. We then evaluate Kneedle's accuracy against existing algorithms on both synthetic and real data sets, and evaluate its performance in two different applications.},
  keywords = {Accuracy,Algorithm design and analysis,Congestion control,Curvature,Detection algorithms,Knee,Knee detection,MapReduce,Noise measurement,Protocols,Sensitivity,System behavior},
  file = {/home/glatzl/Zotero/storage/2XPAJBMW/5961514.html}
}

@incollection{schaeferApplicationCFDUncertainty,
  title = {Application of a {{CFD Uncertainty Quantification Framework}} for {{Industrial-Scale Aerodynamic Analysis}}},
  booktitle = {{{AIAA Scitech}} 2019 {{Forum}}},
  author = {Schaefer, John A. and Cary, Andrew W. and Duque, Earl P. and Lawrence, Seth},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/6.2019-1492},
  urldate = {2024-01-14},
  file = {/home/glatzl/Zotero/storage/DRHAETL5/6.html}
}

@article{schultzNeuralSubstratePrediction1997,
  title = {A {{Neural Substrate}} of {{Prediction}} and {{Reward}}},
  author = {Schultz, Wolfram and Dayan, Peter and Montague, P. Read},
  year = {1997},
  month = mar,
  journal = {Science},
  volume = {275},
  number = {5306},
  pages = {1593--1599},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.275.5306.1593},
  urldate = {2022-11-07},
  abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
  file = {/home/glatzl/Zotero/storage/2G4RWJP9/Schultz et al. - 1997 - A Neural Substrate of Prediction and Reward.pdf}
}

@article{schultzNeuralSubstratePrediction1997a,
  title = {A {{Neural Substrate}} of {{Prediction}} and {{Reward}}},
  author = {Schultz, Wolfram and Dayan, Peter and Montague, P. Read},
  year = {1997},
  month = mar,
  journal = {Science},
  volume = {275},
  number = {5306},
  pages = {1593--1599},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/science.275.5306.1593},
  urldate = {2022-11-07},
  abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
  file = {/home/glatzl/Zotero/storage/3G6TINRI/Schultz et al. - 1997 - A Neural Substrate of Prediction and Reward.pdf}
}

@article{schultzNeuronalActivityMonkey1992,
  title = {Neuronal Activity in Monkey Ventral Striatum Related to the Expectation of Reward},
  author = {Schultz, W. and Apicella, P. and Scarnati, E. and Ljungberg, T.},
  year = {1992},
  month = dec,
  journal = {Journal of Neuroscience},
  volume = {12},
  number = {12},
  pages = {4595--4610},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.12-12-04595.1992},
  urldate = {2022-11-07},
  abstract = {Projections from cortical and subcortical limbic structures to the basal ganglia are predominantly directed to the ventral striatum. The present study investigated how the expectation of external events with behavioral significance is reflected in the activity of ventral striatal neurons. A total of 420 neurons were studied in macaque monkeys performing in a delayed go-no-go task. Lights of different colors instructed the animal to do an arm-reaching movement or refrain from moving, respectively, when a trigger light was illuminated a few seconds later. Task performance was reinforced by liquid reward in both situations. A total of 60 ventral striatal neurons showed sustained increases of activity before the occurrence of individual task events. In 43 of these neurons, activations specifically preceded the delivery of reward, independent of the movement or no-movement reaction. In a series of additional tests, these activations were time locked to the subsequent reward, disappeared within a few trials when reward was omitted, and were temporally unrelated to mouth movements. Changes in the appetitive value of the reward liquid modified the magnitude of activations, suggesting a possible relationship to the hedonic properties of the expected event. Activations also occurred when reward was delivered in a predictable manner outside of any behavioral task. These data suggest that neurons in the ventral striatum are activated during states of expectation of individual environmental events that are predictable to the subject through its past experience. The prevalence of activations related to the expectation of reward suggests that ventral striatal neurons have access to central representations of reward and thereby participate in the processing of information underlying the motivational control of goal-directed behavior.},
  chapter = {Articles},
  copyright = {{\textcopyright} 1992 by Society for Neuroscience},
  langid = {english},
  pmid = {1464759},
  file = {/home/glatzl/Zotero/storage/PCIKEJPY/Schultz et al. - 1992 - Neuronal activity in monkey ventral striatum relat.pdf;/home/glatzl/Zotero/storage/KWWNR6TC/4595.html}
}

@misc{sciencedirectFiniteDifferenceMethods,
  title = {Finite {{Difference Methods}} - an Overview | {{ScienceDirect Topics}}},
  author = {{ScienceDirect}},
  urldate = {2023-05-11},
  howpublished = {https://www.sciencedirect.com/topics/physics-and-astronomy/finite-difference-methods},
  file = {/home/glatzl/Zotero/storage/3WPJCJPF/finite-difference-methods.html}
}

@misc{SetRaspberryPi2021,
  title = {Set {{Up Raspberry Pi DNS Server}} \{\vphantom\}{{Step By Step Guide}}\vphantom\{\}},
  year = {2021},
  month = mar,
  journal = {Knowledge Base by phoenixNAP},
  urldate = {2022-01-06},
  abstract = {Learn how to set up Raspberry Pi DNS server for quicker access to web pages in a few easy to follow steps.},
  howpublished = {https://phoenixnap.com/kb/raspberry-pi-dns-server},
  langid = {american},
  file = {/home/glatzl/Zotero/storage/BH6RZV3D/raspberry-pi-dns-server.html}
}

@misc{shahCycleConsistencyRobustVisual2019,
  title = {Cycle-{{Consistency}} for {{Robust Visual Question Answering}}},
  author = {Shah, Meet and Chen, Xinlei and Rohrbach, Marcus and Parikh, Devi},
  year = {2019},
  month = feb,
  number = {arXiv:1902.05660},
  eprint = {1902.05660},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1902.05660},
  urldate = {2023-12-14},
  abstract = {Despite significant progress in Visual Question Answering over the years, robustness of today's VQA models leave much to be desired. We introduce a new evaluation protocol and associated dataset (VQA-Rephrasings) and show that state-of-the-art VQA models are notoriously brittle to linguistic variations in questions. VQA-Rephrasings contains 3 human-provided rephrasings for 40k questions spanning 40k images from the VQA v2.0 validation dataset. As a step towards improving robustness of VQA models, we propose a model-agnostic framework that exploits cycle consistency. Specifically, we train a model to not only answer a question, but also generate a question conditioned on the answer, such that the answer predicted for the generated question is the same as the ground truth answer to the original question. Without the use of additional annotations, we show that our approach is significantly more robust to linguistic variations than state-of-the-art VQA models, when evaluated on the VQA-Rephrasings dataset. In addition, our approach outperforms state-of-the-art approaches on the standard VQA and Visual Question Generation tasks on the challenging VQA v2.0 dataset.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/glatzl/Zotero/storage/GVRIS767/Shah et al. - 2019 - Cycle-Consistency for Robust Visual Question Answe.pdf;/home/glatzl/Zotero/storage/5GFMNFRT/1902.html}
}

@misc{shakirChestCancerClassification2021,
  title = {Chest {{Cancer Classification VGG}} 16},
  author = {Shakir, Yasir},
  year = {2021},
  month = apr,
  urldate = {2022-12-18}
}

@inproceedings{shengHumanAdversarialVisualQuestion2021,
  title = {Human-{{Adversarial Visual Question Answering}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Sheng, Sasha and Singh, Amanpreet and Goswami, Vedanuj and Magana, Jose and Thrush, Tristan and Galuba, Wojciech and Parikh, Devi and Kiela, Douwe},
  editor = {Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P. S. and Vaughan, J. Wortman},
  year = {2021},
  volume = {34},
  pages = {20346--20359},
  publisher = {{Curran Associates, Inc.}}
}

@misc{siepermannDefinitionKuenstlicheIntelligenz2018,
  type = {{Text}},
  title = {{Definition: K{\"u}nstliche Intelligenz (KI)}},
  shorttitle = {{Definition}},
  author = {Siepermann, Dr. Markus},
  year = {2018},
  month = feb,
  journal = {https://wirtschaftslexikon.gabler.de/definition/kuenstliche-intelligenz-ki-40285},
  publisher = {{Springer Fachmedien Wiesbaden GmbH}},
  urldate = {2022-12-14},
  abstract = {Was ist "K{\"u}nstliche Intelligenz (KI)"? Definition im Gabler Wirtschaftslexikon vollst{\"a}ndig und kostenfrei online. \ding{51}Gepr{\"u}ftes Wissen beim Original.},
  chapter = {economy},
  howpublished = {https://wirtschaftslexikon.gabler.de/definition/kuenstliche-intelligenz-ki-40285},
  langid = {ngerman},
  file = {/home/glatzl/Zotero/storage/RELLTDPX/kuenstliche-intelligenz-ki-40285.html}
}

@article{smithOptimizationTheoryEvolution1978,
  title = {Optimization {{Theory}} in {{Evolution}}},
  author = {Smith, J. Maynard},
  year = {1978},
  journal = {Annual Review of Ecology and Systematics},
  volume = {9},
  number = {1},
  pages = {31--56},
  doi = {10.1146/annurev.es.09.110178.000335},
  urldate = {2022-11-17}
}

@misc{SQLiteHomePage,
  title = {{{SQLite Home Page}}},
  urldate = {2023-05-20},
  howpublished = {https://sqlite.org/index.html},
  file = {/home/glatzl/Zotero/storage/I8S29L4C/index.html}
}

@misc{ST_Crosses,
  title = {{{ST}}\_{{Crosses}}},
  urldate = {2023-05-20},
  howpublished = {https://postgis.net/docs/ST\_Crosses.html},
  file = {/home/glatzl/Zotero/storage/MTVI9H2T/ST_Crosses.html}
}

@misc{strangMultigridMethods2006,
  title = {Multigrid {{Methods}}},
  author = {Strang, Gilbert},
  year = {2006}
}

@article{sunSurrogateModelingFluid2020,
  title = {Surrogate Modeling for Fluid Flows Based on Physics-Constrained Deep Learning without Simulation Data},
  author = {Sun, Luning and Gao, Han and Pan, Shaowu and Wang, Jian-Xun},
  year = {2020},
  month = apr,
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {361},
  pages = {112732},
  issn = {0045-7825},
  doi = {10.1016/j.cma.2019.112732},
  urldate = {2023-05-30},
  abstract = {Numerical simulations on fluid dynamics problems primarily rely on spatially or/and temporally discretization of the governing equation using polynomials into a finite-dimensional algebraic system. Due to the multi-scale nature of the physics and sensitivity from meshing a complicated geometry, such process can be computational prohibitive for most real-time applications (e.g., clinical diagnosis and surgery planning) and many-query analyses (e.g., optimization design and uncertainty quantification). Therefore, developing a cost-effective surrogate model is of great practical significance. Deep learning (DL) has shown new promises for surrogate modeling due to its capability of handling strong nonlinearity and high dimensionality. However, the off-the-shelf DL architectures, success of which heavily relies on the large amount of training data and interpolatory nature of the problem, fail to operate when the data becomes sparse. Unfortunately, data is often insufficient in most parametric fluid dynamics problems since each data point in the parameter space requires an expensive numerical simulation based on the first principle, e.g., Navier{\textendash}Stokes equations. In this paper, we provide a physics-constrained DL approach for surrogate modeling of fluid flows without relying on any simulation data. Specifically, a structured deep neural network (DNN) architecture is devised to enforce the initial and boundary conditions, and the governing partial differential equations (i.e., Navier{\textendash}Stokes equations) are incorporated into the loss of the DNN to drive the training. Numerical experiments are conducted on a number of internal flows relevant to hemodynamics applications, and the forward propagation of uncertainties in fluid properties and domain geometry is studied as well. The results show excellent agreement on the flow field and forward-propagated uncertainties between the DL surrogate approximations and the first-principle numerical simulations.},
  langid = {english},
  keywords = {Cardiovascular flows,Label-free,Navier-Stokes,Neural networks,Physics-informed machine learning,Uncertainty quantification},
  file = {/home/glatzl/Zotero/storage/VYGVCMD3/Sun et al. - 2020 - Surrogate modeling for fluid flows based on physic.pdf;/home/glatzl/Zotero/storage/DN3JY2F3/S004578251930622X.html}
}

@article{sunSurrogateModelingFluid2020a,
  title = {Surrogate Modeling for Fluid Flows Based on Physics-Constrained Deep Learning without Simulation Data},
  author = {Sun, Luning and Gao, Han and Pan, Shaowu and Wang, Jian-Xun},
  year = {2020},
  month = apr,
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {361},
  pages = {112732},
  issn = {0045-7825},
  doi = {10.1016/j.cma.2019.112732},
  urldate = {2024-01-14},
  abstract = {Numerical simulations on fluid dynamics problems primarily rely on spatially or/and temporally discretization of the governing equation using polynomials into a finite-dimensional algebraic system. Due to the multi-scale nature of the physics and sensitivity from meshing a complicated geometry, such process can be computational prohibitive for most real-time applications (e.g., clinical diagnosis and surgery planning) and many-query analyses (e.g., optimization design and uncertainty quantification). Therefore, developing a cost-effective surrogate model is of great practical significance. Deep learning (DL) has shown new promises for surrogate modeling due to its capability of handling strong nonlinearity and high dimensionality. However, the off-the-shelf DL architectures, success of which heavily relies on the large amount of training data and interpolatory nature of the problem, fail to operate when the data becomes sparse. Unfortunately, data is often insufficient in most parametric fluid dynamics problems since each data point in the parameter space requires an expensive numerical simulation based on the first principle, e.g., Navier{\textendash}Stokes equations. In this paper, we provide a physics-constrained DL approach for surrogate modeling of fluid flows without relying on any simulation data. Specifically, a structured deep neural network (DNN) architecture is devised to enforce the initial and boundary conditions, and the governing partial differential equations (i.e., Navier{\textendash}Stokes equations) are incorporated into the loss of the DNN to drive the training. Numerical experiments are conducted on a number of internal flows relevant to hemodynamics applications, and the forward propagation of uncertainties in fluid properties and domain geometry is studied as well. The results show excellent agreement on the flow field and forward-propagated uncertainties between the DL surrogate approximations and the first-principle numerical simulations.},
  keywords = {Cardiovascular flows,Label-free,Navier-Stokes,Neural networks,Physics-informed machine learning,Uncertainty quantification},
  file = {/home/glatzl/Zotero/storage/CYQKGM9Z/Sun et al. - 2020 - Surrogate modeling for fluid flows based on physic.pdf;/home/glatzl/Zotero/storage/FM38T2D4/S004578251930622X.html}
}

@inproceedings{susstrunkOrbisAnnotatorOpen2023,
  title = {Orbis {{Annotator}}: {{An Open Source Toolkit}} for the {{Efficient Annotation}} and {{Refinement}} of {{Text}}},
  booktitle = {Proceedings of the 4th {{Conference}} on {{Language}}, {{Data}} and {{Knowledge}}},
  author = {S{\"u}sstrunk, Norman and Fraefel, Andreas and Weichselbraun, Albert and Brasoveanu, Adrian MP},
  year = {2023},
  pages = {294--305}
}

@article{tangRoleArtificialIntelligence2019,
  title = {The Role of Artificial Intelligence in Medical Imaging Research},
  author = {Tang, Xiaoli},
  year = {2019},
  month = nov,
  journal = {BJR Open},
  volume = {2},
  number = {1},
  pages = {20190031},
  issn = {2513-9878},
  doi = {10.1259/bjro.20190031},
  urldate = {2022-12-14},
  abstract = {Without doubt, artificial intelligence (AI) is the most discussed topic today in medical imaging research, both in diagnostic and therapeutic. For diagnostic imaging alone, the number of publications on AI has increased from about 100{\textendash}150 per year in 2007{\textendash}2008 to 1000{\textendash}1100 per year in 2017{\textendash}2018. Researchers have applied AI to automatically recognizing complex patterns in imaging data and providing quantitative assessments of radiographic characteristics. In radiation oncology, AI has been applied on different image modalities that are used at different stages of the treatment. i.e. tumor delineation and treatment assessment. Radiomics, the extraction of a large number of image features from radiation images with a high-throughput approach, is one of the most popular research topics today in medical imaging research. AI is the essential boosting power of processing massive number of medical images and therefore uncovers disease characteristics that fail to be appreciated by the naked eyes. The objectives of this paper are to review the history of AI in medical imaging research, the current role, the challenges need to be resolved before AI can be adopted widely in the clinic, and the potential future.},
  pmcid = {PMC7594889},
  pmid = {33178962},
  file = {/home/glatzl/Zotero/storage/8T6LLNG6/Tang - 2019 - The role of artificial intelligence in medical ima.pdf}
}

@misc{tocchettiRobustnessHumanCenteredPerspective2022,
  title = {A.{{I}}. {{Robustness}}: A {{Human-Centered Perspective}} on {{Technological Challenges}} and {{Opportunities}}},
  shorttitle = {A.{{I}}. {{Robustness}}},
  author = {Tocchetti, Andrea and Corti, Lorenzo and Balayn, Agathe and Yurrita, Mireia and Lippmann, Philip and Brambilla, Marco and Yang, Jie},
  year = {2022},
  month = oct,
  number = {arXiv:2210.08906},
  eprint = {2210.08906},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2210.08906},
  urldate = {2023-09-19},
  abstract = {Despite the impressive performance of Artificial Intelligence (AI) systems, their robustness remains elusive and constitutes a key issue that impedes large-scale adoption. Robustness has been studied in many domains of AI, yet with different interpretations across domains and contexts. In this work, we systematically survey the recent progress to provide a reconciled terminology of concepts around AI robustness. We introduce three taxonomies to organize and describe the literature both from a fundamental and applied point of view: 1) robustness by methods and approaches in different phases of the machine learning pipeline; 2) robustness for specific model architectures, tasks, and systems; and in addition, 3) robustness assessment methodologies and insights, particularly the trade-offs with other trustworthiness properties. Finally, we identify and discuss research gaps and opportunities and give an outlook on the field. We highlight the central role of humans in evaluating and enhancing AI robustness, considering the necessary knowledge humans can provide, and discuss the need for better understanding practices and developing supportive tools in the future.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/home/glatzl/Zotero/storage/IGW85MJX/Tocchetti et al. - 2022 - A.I. Robustness a Human-Centered Perspective on T.pdf;/home/glatzl/Zotero/storage/G3PC7SBR/2210.html}
}

@article{tominagaAccuracyCFDSimulations2023,
  title = {Accuracy of {{CFD}} Simulations in Urban Aerodynamics and Microclimate: {{Progress}} and Challenges},
  shorttitle = {Accuracy of {{CFD}} Simulations in Urban Aerodynamics and Microclimate},
  author = {Tominaga, Yoshihide and Wang, Liangzhu (Leon) and Zhai, Zhiqiang (John) and Stathopoulos, Ted},
  year = {2023},
  month = sep,
  journal = {Building and Environment},
  volume = {243},
  pages = {110723},
  issn = {0360-1323},
  doi = {10.1016/j.buildenv.2023.110723},
  urldate = {2024-01-14},
  abstract = {This review outlines historical and recent research progress on the accuracy of computational fluid dynamics (CFD) simulations of urban aerodynamics and microclimates and clarifies future research directions and significant challenges for accuracy and reliability using CFD in this field. First, the development and accepted concepts of verification and validation (V\&V) and uncertainty quantification (UQ) in general computer simulations and CFD are reviewed. Subsequently, progress made in V\&V and UQ for urban aerodynamics and microclimate CFD simulations is described. The required or acceptable accuracy in this field has been discussed in several studies; however, challenges specific to applying CFD in this area should be recognized considering that the target phenomenon in urban aerodynamics and microclimates is complex. In addition, constructing a conceptual model is challenging and has many uncertainties. Furthermore, this field is characterized by significant spatial distributions of physical quantities, such as wind speed, temperature, and other scalar variables; thus, specific validation metrics and multilateral methods, including a conventional profile comparison, should be used. Therefore, the V\&V and UQ processes should be implemented thoroughly, considering the characteristics of urban aerodynamics and microclimates. Discussions presented in this paper are of utmost importance and very timely in terms of simulation quality controls, especially during this new era of machine learning and artificial intelligence-based models that started being applied to urban aerodynamics and microclimate predictions.},
  keywords = {Computational fluid dynamics simulation,Uncertainty quantification,Urban aerodynamics,Urban microclimate,Verification and validation},
  file = {/home/glatzl/Zotero/storage/Z9SRNC53/S0360132323007503.html}
}

@article{tysonHigherorderErrorEstimation2019,
  title = {A Higher-Order Error Estimation Framework for Finite-Volume {{CFD}}},
  author = {Tyson, William C. and Roy, Christopher J.},
  year = {2019},
  month = oct,
  journal = {Journal of Computational Physics},
  volume = {394},
  pages = {632--657},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2019.06.017},
  urldate = {2024-01-14},
  abstract = {Computational fluid dynamics is an invaluable tool for both the design and analysis of aerospace vehicles. Reliable error estimation techniques are needed to ensure that simulation results are accurate enough to be used in engineering decision-making processes. In this work, a framework for estimating error and improving solution accuracy is presented. A linearized error transport equation (ETE) is used to estimate local discretization errors. A truncation error estimation technique is proposed which combines aspects of higher-order residual methods and continuous residual methods. The equivalence between adjoint and ETE methods for functional error estimation is demonstrated. Using adjoint/ETE equivalence, the higher-order properties of adjoint methods are extended to ETE methods. Consequently, ETE error estimates are shown to converge to the true discretization error at a higher-order rate. ETE error estimates are then used to correct the entire primal solution, and by extension, all output functionals, to higher order. The computational advantages of this ETE approach are discussed. Results are presented for 1D and 2D inviscid and viscous flow problems on grids with smoothly varying and non-smoothly varying grid metrics.},
  keywords = {Computational fluid dynamics,Discrete adjoint method,Discretization error estimation,Error transport equations,Finite-volume method,Truncation error estimation},
  file = {/home/glatzl/Zotero/storage/7FMKG77A/S0021999119304243.html}
}

@misc{u.ghiak.n.ghiac.t.shinHighRESolutionsIncompressible1982,
  title = {High-{{RE Solutions}} for {{Incompressible Flow Using}} the {{Navier-Stokes Equations}} and a {{Multigrid Method}}},
  author = {{U. Ghia, K. N. Ghia, C. T. Shin}},
  year = {1982},
  month = jan,
  publisher = {{Journal of Computational Physics 48}},
  langid = {english}
}

@misc{universitaetsspitalzuerichLungenkrebs2022,
  title = {{Lungenkrebs}},
  author = {Universit{\"a}tsspital Z{\"u}rich},
  year = {2022},
  month = oct,
  journal = {Universit{\"a}tsspital Z{\"u}rich},
  urldate = {2022-12-14},
  abstract = {Lungenkrebs ist ein b{\"o}sartiger Tumor in der Lunge, der sehr gef{\"a}hrlich ist. Er verursacht oft erst sp{\"a}t Symptome wie Husten oder Kurzatmigkeit. Der Hauptgrund f{\"u}r die Entwicklung von Lungenkrebs ist das Rauchen.},
  langid = {ngerman},
  file = {/home/glatzl/Zotero/storage/LTJPU32N/lungenkrebs.html}
}

@misc{vanheeswijkFourPolicyClasses2021,
  title = {The {{Four Policy Classes}} of {{Reinforcement Learning}}},
  author = {{van Heeswijk}, Wouter},
  year = {2021},
  month = jul,
  journal = {Medium},
  urldate = {2022-12-11},
  abstract = {Policies in Reinforcement Learning (RL) are shrouded in a certain mystique. Simply stated, a policy {$\pi$}: s {\textrightarrow}a is any function that returns a feasible action for a problem. No less, no more. For{\ldots}},
  howpublished = {https://towardsdatascience.com/the-four-policy-classes-of-reinforcement-learning-38185daa6c8a},
  langid = {english},
  file = {/home/glatzl/Zotero/storage/657722FL/the-four-policy-classes-of-reinforcement-learning-38185daa6c8a.html}
}

@incollection{vanotterloReinforcementLearningMarkov2012,
  title = {Reinforcement {{Learning}} and {{Markov Decision Processes}}},
  booktitle = {Reinforcement {{Learning}}: {{State-of-the-Art}}},
  author = {{van Otterlo}, Martijn and Wiering, Marco},
  editor = {Wiering, Marco and {van Otterlo}, Martijn},
  year = {2012},
  series = {Adaptation, {{Learning}}, and {{Optimization}}},
  pages = {3--42},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-27645-3_1},
  urldate = {2022-10-06},
  abstract = {Situated in between supervised learning and unsupervised learning, the paradigm of reinforcement learning deals with learning in sequential decision making problems in which there is limited feedback. This text introduces the intuitions and concepts behind Markov decision processes and two classes of algorithms for computing optimal behaviors: reinforcement learning and dynamic programming. First the formal framework of Markov decision process is defined, accompanied by the definition of value functions and policies. The main part of this text deals with introducing foundational classes of algorithms for learning optimal behaviors, based on various definitions of optimality with respect to the goal of learning sequential decisions. Additionally, it surveys efficient extensions of the foundational algorithms, differing mainly in the way feedback given by the environment is used to speed up learning, and in the way they concentrate on relevant parts of the problem. For both model-based and model-free settings these efficient extensions have shown useful in scaling up to larger problems.},
  isbn = {978-3-642-27645-3},
  langid = {english},
  keywords = {Goal State,Markov Decision Process,Monte Carlo,Optimal Policy,Reward Function}
}

@misc{VertexAI,
  title = {{Vertex AI}},
  journal = {Google Cloud},
  urldate = {2022-12-18},
  abstract = {Schnelle, skalierbare und nutzerfreundliche KI-Technologien. Details zu KI-, Netzwerk-KI- und k{\"u}nstlicher Intelligenz-Feldverzweigungen in Google Cloud.},
  howpublished = {https://cloud.google.com/vertex-ai?hl=de},
  langid = {ngerman},
  file = {/home/glatzl/Zotero/storage/F7ZEPCA2/vertex-ai.html}
}

@misc{wangFVQAFactbasedVisual2017,
  title = {{{FVQA}}: {{Fact-based Visual Question Answering}}},
  shorttitle = {{{FVQA}}},
  author = {Wang, Peng and Wu, Qi and Shen, Chunhua and van den Hengel, Anton and Dick, Anthony},
  year = {2017},
  month = aug,
  number = {arXiv:1606.05433},
  eprint = {1606.05433},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-10-24},
  abstract = {Visual Question Answering (VQA) has attracted a lot of attention in both Computer Vision and Natural Language Processing communities, not least because it offers insight into the relationships between two important sources of information. Current datasets, and the models built upon them, have focused on questions which are answerable by direct analysis of the question and image alone. The set of such questions that require no external information to answer is interesting, but very limited. It excludes questions which require common sense, or basic factual knowledge to answer, for example. Here we introduce FVQA, a VQA dataset which requires, and supports, much deeper reasoning. FVQA only contains questions which require external information to answer. We thus extend a conventional visual question answering dataset, which contains image-question-answerg triplets, through additional image-question-answer-supporting fact tuples. The supporting fact is represented as a structural triplet, such as {$<$}Cat,CapableOf,ClimbingTrees{$>$}. We evaluate several baseline models on the FVQA dataset, and describe a novel model which is capable of reasoning about an image on the basis of supporting facts.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/glatzl/Zotero/storage/IDXYDXBW/Wang et al. - 2017 - FVQA Fact-based Visual Question Answering.pdf;/home/glatzl/Zotero/storage/UBXV5FDK/1606.html}
}

@article{wangText3D3DConvolutional2023,
  title = {{{Text3D}}: {{3D Convolutional Neural Networks}} for {{Text Classification}}},
  author = {Wang, Jinrui and Li, Jie and Zhang, Yirui},
  year = {2023},
  journal = {Electronics},
  volume = {12},
  number = {14},
  issn = {2079-9292},
  doi = {10.3390/electronics12143087},
  abstract = {Convolutional Neural Networks (CNNs) have demonstrated promising performance in many NLP tasks owing to their excellent local feature-extraction capability. Many previous works have made word-level 2D CNNs deeper to capture global representations of text. Three-dimensional CNNs perform excellently in CV tasks through spatiotemporal feature learning, though they are little utilized in text classification task. This paper proposes a simple, yet effective, approach for hierarchy feature learning using 3D CNN in text classification tasks, named Text3D. Text3D efficiently extracts rich information through text representations structured in three dimensions produced by pretrained language model BERT. Specifically, our Text3D utilizes word order, word embedding and hierarchy information of BERT encoder layers as features of three dimensions. The proposed model with 12 layers outperforms the baselines on four benchmark datasets for sentiment classification and topic categorization. Text3D with a different hierarchy of output from BERT layers demonstrates that the linguistic features from different layers have varied effects on text classification.}
}

@misc{WasIstCURL2020,
  title = {{Was ist cURL? Was kann das Open Source Tool?}},
  shorttitle = {{Was ist cURL?}},
  year = {2020},
  month = apr,
  journal = {Host Europe Blog},
  urldate = {2022-01-06},
  abstract = {Das weitverbreitete Open-Source-Kommandozeilenprogramm cURL ist schon l{\"a}nger in Linux-Systemen integriert. Erfahren Sie mehr {\"u}ber dieses praktische Tool!},
  langid = {ngerman},
  file = {/home/glatzl/Zotero/storage/5NCGKS5B/was-ist-curl.html}
}

@phdthesis{watkinsLearningDelayedRewards1989,
  title = {Learning from {{Delayed Rewards}}},
  author = {Watkins, Christopher},
  year = {1989}
}

@misc{WhatAreNoSQL,
  title = {What Are {{NoSQL Databases}}? | {{IBM}}},
  shorttitle = {What Are {{NoSQL Databases}}?},
  urldate = {2023-05-20},
  abstract = {NoSQL, also referred to as ``not only SQL'', ``non-SQL'', is an approach to database design that enables the storage and\,querying\,of data outside the traditional structures found in\,relational databases.},
  howpublished = {https://www.ibm.com/topics/nosql-databases},
  langid = {american}
}

@misc{WhatInMemoryDatabase,
  title = {What {{Is}} an {{In-Memory Database}}?},
  journal = {Amazon Web Services, Inc.},
  urldate = {2023-05-20},
  howpublished = {https://aws.amazon.com/nosql/in-memory/},
  langid = {american},
  file = {/home/glatzl/Zotero/storage/G9SYIPFR/in-memory.html}
}

@misc{whitakerSynapticStrippingHow2023,
  title = {Synaptic {{Stripping}}: {{How Pruning Can Bring Dead Neurons Back To Life}}},
  shorttitle = {Synaptic {{Stripping}}},
  author = {Whitaker, Tim and Whitley, Darrell},
  year = {2023},
  month = feb,
  number = {arXiv:2302.05818},
  eprint = {2302.05818},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2302.05818},
  urldate = {2023-09-18},
  abstract = {Rectified Linear Units (ReLU) are the default choice for activation functions in deep neural networks. While they demonstrate excellent empirical performance, ReLU activations can fall victim to the dead neuron problem. In these cases, the weights feeding into a neuron end up being pushed into a state where the neuron outputs zero for all inputs. Consequently, the gradient is also zero for all inputs, which means that the weights which feed into the neuron cannot update. The neuron is not able to recover from direct back propagation and model capacity is reduced as those parameters can no longer be further optimized. Inspired by a neurological process of the same name, we introduce Synaptic Stripping as a means to combat this dead neuron problem. By automatically removing problematic connections during training, we can regenerate dead neurons and significantly improve model capacity and parametric utilization. Synaptic Stripping is easy to implement and results in sparse networks that are more efficient than the dense networks they are derived from. We conduct several ablation studies to investigate these dynamics as a function of network width and depth and we conduct an exploration of Synaptic Stripping with Vision Transformers on a variety of benchmark datasets.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/home/glatzl/Zotero/storage/HQCZ968B/Whitaker and Whitley - 2023 - Synaptic Stripping How Pruning Can Bring Dead Neu.pdf;/home/glatzl/Zotero/storage/9U6IMBYJ/2302.html}
}

@article{xueForecastingHourlyAttraction2023,
  title = {Forecasting Hourly Attraction Tourist Volume with Search Engine and Social Media Data for Decision Support},
  author = {Xue, Gang and Liu, Shifeng and Ren, Long and Gong, Daqing},
  year = {2023},
  month = jul,
  journal = {Information Processing and Management},
  volume = {60},
  number = {4},
  pages = {103399},
  doi = {10.1016/j.ipm.2023.103399}
}

@misc{xuShowAttendTell2016,
  title = {Show, {{Attend}} and {{Tell}}: {{Neural Image Caption Generation}} with {{Visual Attention}}},
  shorttitle = {Show, {{Attend}} and {{Tell}}},
  author = {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},
  year = {2016},
  month = apr,
  number = {arXiv:1502.03044},
  eprint = {1502.03044},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-10-24},
  abstract = {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/glatzl/Zotero/storage/5YC64XAH/Xu et al. - 2016 - Show, Attend and Tell Neural Image Caption Genera.pdf;/home/glatzl/Zotero/storage/3VSM3C68/1502.html}
}

@article{yanAchievingHumanParity2023,
  title = {Achieving {{Human Parity}} on {{Visual Question Answering}}},
  author = {Yan, Ming and Xu, Haiyang and Li, Chenliang and Tian, Junfeng and Bi, Bin and Wang, Wei and Xu, Xianzhe and Zhang, Ji and Huang, Songfang and Huang, Fei and Si, Luo and Jin, Rong},
  year = {2023},
  month = apr,
  journal = {ACM Transactions on Information Systems},
  volume = {41},
  number = {3},
  pages = {79:1--79:40},
  issn = {1046-8188},
  doi = {10.1145/3572833},
  urldate = {2023-10-24},
  abstract = {The Visual Question Answering (VQA) task utilizes both visual image and language analysis to answer a textual question with respect to an image. It has been a popular research topic with an increasing number of real-world applications in the last decade. This paper introduces a novel hierarchical integration of vision and language AliceMind-MMU (ALIbaba's Collection of Encoder-decoders from Machine IntelligeNce lab of Damo academy - MultiMedia Understanding), which leads to similar or even slightly better results than a human being does on VQA. A hierarchical framework is designed to tackle the practical problems of VQA in a cascade manner including: (1) diverse visual semantics learning for comprehensive image content understanding; (2) enhanced multi-modal pre-training with modality adaptive attention; and (3) a knowledge-guided model integration with three specialized expert modules for the complex VQA task. Treating different types of visual questions with corresponding expertise needed plays an important role in boosting the performance of our VQA architecture up to the human level. An extensive set of experiments and analysis are conducted to demonstrate the effectiveness of the new research work.},
  keywords = {cross-modal interaction,multi-modal pre-training,text and image content analysis,Visual Question Answering,visual reasoning},
  file = {/home/glatzl/Zotero/storage/YUYB9JDE/Yan et al. - 2023 - Achieving Human Parity on Visual Question Answerin.pdf}
}

@article{yuCrossmodalKnowledgeReasoning2020,
  title = {Cross-Modal Knowledge Reasoning for Knowledge-Based Visual Question Answering},
  author = {Yu, Jing and Zhu, Zihao and Wang, Yujing and Zhang, Weifeng and Hu, Yue and Tan, Jianlong},
  year = {2020},
  month = dec,
  journal = {Pattern Recognition},
  volume = {108},
  pages = {107563},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2020.107563},
  urldate = {2023-10-24},
  abstract = {Knowledge-based Visual Question Answering (KVQA) requires external knowledge beyond the visible content to answer questions about an image. This ability is challenging but indispensable to achieve general VQA. One limitation of existing KVQA solutions is that they jointly embed all kinds of information without fine-grained selection, which introduces unexpected noises for reasoning the correct answer. How to capture the question-oriented and information-complementary evidence remains a key challenge to solve the problem. Inspired by the human cognition theory, in this paper, we depict an image by multiple knowledge graphs from the visual, semantic and factual views. Thereinto, the visual graph and semantic graph are regarded as image-conditioned instantiation of the factual graph. On top of these new representations, we re-formulate Knowledge-based Visual Question Answering as a recurrent reasoning process for obtaining complementary evidence from multimodal information. To this end, we decompose the model into a series of memory-based reasoning steps, each performed by a Graph-based Read, Update, and Control (GRUC) module that conducts parallel reasoning over both visual and semantic information. By stacking the modules multiple times, our model performs transitive reasoning and obtains question-oriented concept representations under the constrain of different modalities. Finally, we perform graph neural networks to infer the global-optimal answer by jointly considering all the concepts. We achieve a new state-of-the-art performance on three popular benchmark datasets, including FVQA, Visual7W-KB and OK-VQA, and demonstrate the effectiveness and interpretability of our model with extensive experiments. The source code is available at: https://github.com/astro-zihao/gruc},
  keywords = {Compositional reasoning module,Cross-modal knowledge reasoning,Explainable reasoning,Knowledge-based visual question answering,Multimodal knowledge graphs},
  file = {/home/glatzl/Zotero/storage/VZ44YL9E/Yu et al. - 2020 - Cross-modal knowledge reasoning for knowledge-base.pdf;/home/glatzl/Zotero/storage/EVN6R4LM/S0031320320303666.html}
}

@misc{yuDeepModularCoAttention2019,
  title = {Deep {{Modular Co-Attention Networks}} for {{Visual Question Answering}}},
  author = {Yu, Zhou and Yu, Jun and Cui, Yuhao and Tao, Dacheng and Tian, Qi},
  year = {2019},
  month = jun,
  number = {arXiv:1906.10770},
  eprint = {1906.10770},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-10-24},
  abstract = {Visual Question Answering (VQA) requires a fine-grained and simultaneous understanding of both the visual content of images and the textual content of questions. Therefore, designing an effective `co-attention' model to associate key words in questions with key objects in images is central to VQA performance. So far, most successful attempts at co-attention learning have been achieved by using shallow models, and deep co-attention models show little improvement over their shallow counterparts. In this paper, we propose a deep Modular Co-Attention Network (MCAN) that consists of Modular Co-Attention (MCA) layers cascaded in depth. Each MCA layer models the self-attention of questions and images, as well as the guided-attention of images jointly using a modular composition of two basic attention units. We quantitatively and qualitatively evaluate MCAN on the benchmark VQA-v2 dataset and conduct extensive ablation studies to explore the reasons behind MCAN's effectiveness. Experimental results demonstrate that MCAN significantly outperforms the previous state-of-the-art. Our best single model delivers 70.63\${\textbackslash}\%\$ overall accuracy on the test-dev set. Code is available at https://github.com/MILVLG/mcan-vqa.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/glatzl/Zotero/storage/STBGA9U3/Yu et al. - 2019 - Deep Modular Co-Attention Networks for Visual Ques.pdf;/home/glatzl/Zotero/storage/L2MRCD5X/1906.html}
}

@article{zarezadehOnlineTouristInformation2023,
  title = {Online Tourist Information Search Strategies},
  author = {Zarezadeh, Zohreh and Benckendorff, Pierre and Gretzel, Ulrike},
  year = {2023},
  month = sep,
  journal = {Tourism Management Perspectives},
  volume = {48},
  pages = {101140},
  doi = {10.1016/j.tmp.2023.101140}
}

@misc{zhangDeepNetworkApproximation2023,
  title = {Deep {{Network Approximation}}: {{Beyond ReLU}} to {{Diverse Activation Functions}}},
  shorttitle = {Deep {{Network Approximation}}},
  author = {Zhang, Shijun and Lu, Jianfeng and Zhao, Hongkai},
  year = {2023},
  month = sep,
  number = {arXiv:2307.06555},
  eprint = {2307.06555},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2307.06555},
  urldate = {2023-09-18},
  abstract = {This paper explores the expressive power of deep neural networks for a diverse range of activation functions. An activation function set \${\textbackslash}mathscr\{A\}\$ is defined to encompass the majority of commonly used activation functions, such as \${\textbackslash}mathtt\{ReLU\}\$, \${\textbackslash}mathtt\{LeakyReLU\}\$, \${\textbackslash}mathtt\{ReLU\}\^2\$, \${\textbackslash}mathtt\{ELU\}\$, \${\textbackslash}mathtt\{SELU\}\$, \${\textbackslash}mathtt\{Softplus\}\$, \${\textbackslash}mathtt\{GELU\}\$, \${\textbackslash}mathtt\{SiLU\}\$, \${\textbackslash}mathtt\{Swish\}\$, \${\textbackslash}mathtt\{Mish\}\$, \${\textbackslash}mathtt\{Sigmoid\}\$, \${\textbackslash}mathtt\{Tanh\}\$, \${\textbackslash}mathtt\{Arctan\}\$, \${\textbackslash}mathtt\{Softsign\}\$, \${\textbackslash}mathtt\{dSiLU\}\$, and \${\textbackslash}mathtt\{SRS\}\$. We demonstrate that for any activation function \${\textbackslash}varrho{\textbackslash}in {\textbackslash}mathscr\{A\}\$, a \${\textbackslash}mathtt\{ReLU\}\$ network of width \$N\$ and depth \$L\$ can be approximated to arbitrary precision by a \${\textbackslash}varrho\$-activated network of width \$4N\$ and depth \$2L\$ on any bounded set. This finding enables the extension of most approximation results achieved with \${\textbackslash}mathtt\{ReLU\}\$ networks to a wide variety of other activation functions, at the cost of slightly larger constants.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/glatzl/Zotero/storage/M39YYH8L/Zhang et al. - 2023 - Deep Network Approximation Beyond ReLU to Diverse.pdf;/home/glatzl/Zotero/storage/UKF7GS8L/2307.html}
}

@misc{zhangWhyShallowNetworks2023,
  title = {Why {{Shallow Networks Struggle}} with {{Approximating}} and {{Learning High Frequency}}: {{A Numerical Study}}},
  shorttitle = {Why {{Shallow Networks Struggle}} with {{Approximating}} and {{Learning High Frequency}}},
  author = {Zhang, Shijun and Zhao, Hongkai and Zhong, Yimin and Zhou, Haomin},
  year = {2023},
  month = jun,
  number = {arXiv:2306.17301},
  eprint = {2306.17301},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2306.17301},
  urldate = {2023-09-18},
  abstract = {In this work, a comprehensive numerical study involving analysis and experiments shows why a two-layer neural network has difficulties handling high frequencies in approximation and learning when machine precision and computation cost are important factors in real practice. In particular, the following fundamental computational issues are investigated: (1) the best accuracy one can achieve given a finite machine precision, (2) the computation cost to achieve a given accuracy, and (3) stability with respect to perturbations. The key to the study is the spectral analysis of the corresponding Gram matrix of the activation functions which also shows how the properties of the activation function play a role in the picture.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  file = {/home/glatzl/Zotero/storage/B999I9KU/Zhang et al. - 2023 - Why Shallow Networks Struggle with Approximating a.pdf;/home/glatzl/Zotero/storage/52U75LT6/2306.html}
}

@inproceedings{zhangYinYangBalancing2016,
  title = {Yin and {{Yang}}: {{Balancing}} and {{Answering Binary Visual Questions}}},
  booktitle = {Conference on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Zhang, Peng and Goyal, Yash and {Summers-Stay}, Douglas and Batra, Dhruv and Parikh, Devi},
  year = {2016}
}
